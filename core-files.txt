
=== src/index.ts ===

import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
import { readFile, mkdir, readdir, access, writeFile } from 'fs/promises';
import { config } from 'dotenv';
import { dirname, join } from 'path';
import * as path from 'path';
import { fileURLToPath } from 'url';
import { runMotherAgent } from './mother-agent.js';
import { getProjectId } from './util/sanitize.js';
import { writeObservation } from './util/observations.js';
import { exec, spawn, ChildProcess } from 'child_process';
import { promisify } from 'util';
import { homedir } from "node:os";

const execPromise = promisify(exec);

function winRoamingBin(): string {
  // VS Code spawns MCP servers with a clean env (no APPDATA)
  const base = process.env.APPDATA ?? path.join(homedir(), "AppData", "Roaming");
  return path.join(base, "npm");
}

// Function to find tool paths during initialization
async function findToolPaths() {
  const isWindows = process.platform === 'win32';
  
  let npxPath, uvxPath;

  if (isWindows) {
    try {
      const npxPaths = (await execPromise('cmd.exe /c where npx.cmd')).stdout.trim().split('\n');
      // Favor Program Files to get direct executable
      const foundNpxPath = npxPaths.find(p => p.includes('Program Files'));
      if (!foundNpxPath) {
        throw new Error('Could not find npx.cmd in Program Files');
      }
      npxPath = path.normalize(foundNpxPath).trim();

      uvxPath = path.normalize((await execPromise('cmd.exe /c where uvx.exe')).stdout.trim().split('\n')[0]).trim();
    } catch (err) {
      throw new Error(`Failed to find tool paths: ${err}`);
    }
  }else {
    npxPath = (await execPromise('which npx')).stdout.trim();
    uvxPath = (await execPromise('which uvx')).stdout.trim();
  }

  // Store normalized paths
  process.env.DEEBO_NPX_PATH = npxPath;
  process.env.DEEBO_UVX_PATH = uvxPath;

  // Get npm bin directory for Windows desktop-commander.cmd
  const npmBin = isWindows
    ? winRoamingBin()                                  // Use homedir() when VS Code strips env
    : path.dirname(npxPath);                           // same folder as npx on *nix

  process.env.DEEBO_NPM_BIN = npmBin;                 // <-- expose for later
  
  return { npxPath, uvxPath, npmBin };
}

// Helper to find session directory
async function findSessionDir(sessionId: string): Promise<string | null> {
  const memoryBank = join(DEEBO_ROOT, 'memory-bank');
  const projects = await readdir(memoryBank);
  
  for (const project of projects) {
    const sessionPath = join(memoryBank, project, 'sessions', sessionId);
    try {
      await access(sessionPath);
      return sessionPath;
    } catch {
      continue;
    }
  }
  return null;
}

// Registry to track active sessions and their associated processes/controllers
const processRegistry = new Map<string, {
  motherController: AbortController;
  scenarioPids: Set<number>; // Store PIDs of spawned scenario agents
}>();

// Track terminated PIDs across all tools
const terminatedPids = new Set<number>();

// Load environment variables from .env file
config();

// Validate required environment variables
if (!process.env.MOTHER_MODEL) {
  throw new Error('MOTHER_MODEL environment variable is required');
}
if (!process.env.SCENARIO_MODEL) {
  throw new Error('SCENARIO_MODEL environment variable is required');
}


// Set up basic directories
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
export const DEEBO_ROOT = join(__dirname, '..');

// Create required directories
await mkdir(join(DEEBO_ROOT, 'memory-bank'), { recursive: true });

// Find and configure tool paths
await findToolPaths();

// Create MCP server
const server = new McpServer({
 name: "Deebo",
 version: "1.0.0"
});

// Register start tool - begins a debug session
server.tool(
  "start",
  "Begins an autonomous debugging session that investigates software bugs through multiple competing hypotheses. This tool launches a mother agent that analyzes errors, generates diverse hypotheses about potential causes, and spawns isolated scenario agents to test each hypothesis in separate git branches. The mother agent coordinates the investigation, evaluates scenario reports, and synthesizes a validated solution when sufficient evidence is found.",
  {
    error: z.string().describe("The error message or description of the bug to investigate"),
    repoPath: z.string().describe("Absolute path to the git repository containing the code to debug"),
    context: z.string().optional().describe("Additional context like code snippets, previous attempts, or relevant information"),
    language: z.string().optional().describe("Programming language of the code being debugged (e.g., 'typescript', 'python')"),
    filePath: z.string().optional().describe("Relative path to the specific file containing the bug, if known")
  },
  async ({ error, repoPath, context, language, filePath }, extra) => {
    const projectId = getProjectId(repoPath);
    const sessionId = `session-${Date.now()}`;
    await mkdir(join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'logs'), { recursive: true });
    await mkdir(join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'reports'), { recursive: true });

    // Create controller and PID set for this session
    const motherController = new AbortController();
    const scenarioPids = new Set<number>();

    // Register the session
    processRegistry.set(sessionId, {
      motherController,
      scenarioPids
    });
    // console.log(`Registered session ${sessionId}`); // Removed informational log

    // Run mother agent in background, passing the signal and PID set
    // Note: runMotherAgent signature needs to be updated in mother-agent.ts to accept these
    runMotherAgent(
      sessionId,
      error,
      context ?? "",
      language ?? "typescript",
      filePath ?? "",
      repoPath,
      motherController.signal, // Pass the signal
      scenarioPids // Pass the Set for tracking scenario PIDs
    ).catch(err => {
      console.error(`Debug session ${sessionId} failed during execution:`, err);
      // Clean up registry if mother agent fails during execution
      processRegistry.delete(sessionId);
    }).finally(() => {
      // Optional: Could also remove from registry on normal completion,
      // but cancel needs to handle the case where it's still running.
      // For now, only removing on error/cancel.
      // console.log(`Mother agent promise settled for session ${sessionId}.`); // Removed internal log
    });

    // Return session ID immediately
    return {
      content: [{
        type: "text",
        text:
          `Session ${sessionId} started!\n\n` +
          `Check out the GitHub for tips and best practices:\n` +
          `https://github.com/snagasuri/deebo-prototype\n\n` +
          `Reminder: Deebo updates frequently.\n` +
          `Run npx deebo-setup@latest or pull the latest from GitHub occasionally to get bug fixes and improvements!`
      }]
    };
  }
);

// Register check tool - gets status of a debug session
server.tool(
  "check",
  "Retrieves the current status of a debugging session, providing a detailed pulse report. For in-progress sessions, the pulse includes the mother agent's current stage in the OODA loop, running scenario agents with their hypotheses, and any preliminary findings. For completed sessions, the pulse contains the final solution with a comprehensive explanation, relevant code changes, and outcome summaries from all scenario agents that contributed to the solution. Use this tool to monitor ongoing progress or retrieve the final validated fix.",
  {
    sessionId: z.string().describe("The session ID returned by the start tool when the debugging session was initiated")
  },
  async ({ sessionId }, extra) => {
    try {
      const sessionDir = await findSessionDir(sessionId);
      if (!sessionDir) {
        return {
          content: [{ 
            type: "text",
            text: `Session ${sessionId} not found`
          }]
        };
      }

      // Get time metrics and mother status
      const logsDir = join(sessionDir, 'logs');
      const motherLogPath = join(logsDir, 'mother.log');
      const motherLog = await readFile(motherLogPath, 'utf8');
      const motherLines = motherLog.split('\n').filter(Boolean);

      if (!motherLines.length) return { content: [{ type: "text", text: 'Session initializing' }] };

      const firstEvent = JSON.parse(motherLines[0]);
      const durationMs = Date.now() - new Date(firstEvent.timestamp).getTime();

      // Determine status by scanning for solution tag, cancellation, or errors
      let status = 'in_progress'; // Default status
      let solutionFoundInScan = false;
      let lastValidEvent: any = null; // Store the last successfully parsed event
      let solutionContent = ''; // Store solution content when found
      // Use module-level terminatedPids set

      for (let i = motherLines.length - 1; i >= 0; i--) {
        try {
          const event = JSON.parse(motherLines[i]);
          if (!lastValidEvent) lastValidEvent = event; // Capture the last valid event

          const content = event.data?.response || event.data?.response?.content || event.message || '';
          
          // Check for process spawn and termination with comprehensive pattern
          const SCENARIO_PID_PATTERN = /(?:Spawned|Removed|Terminated|Cancelled) Scenario .* PID (\d+)/;
          const pidMatch = content.match(SCENARIO_PID_PATTERN);
          if (pidMatch) {
            const pid = parseInt(pidMatch[1]);
            // Check for any termination-related terms
            if (content.match(/(Removed|Terminated|Cancelled)/)) {
              terminatedPids.add(pid);
            }
          }
          
          // Check for session cancellation
          if (content.includes('Session cancelled by user request')) {
            status = 'cancelled';
            break;
          }
          
          // Check for solution tag or completion message
          if (content.includes('<solution>')) {
            const match = content.match(/<solution>([\s\S]*?)<\/solution>/);
            if (match && match[1].trim()) {
              status = 'completed';
              solutionFoundInScan = true;
              solutionContent = match[1].trim();
              // Don't break - keep scanning to gather all info
            }
          } else if (content === 'Solution found or investigation concluded.') {
            status = 'completed';
            solutionFoundInScan = true;
            // Don't break - keep scanning to find solution content
          }
          
          // Check for error status
          if (event.level === 'error') {
            status = 'failed';
            // Continue scanning for potential solution or cancellation
          }
        } catch (e) {
          // Skip invalid JSON lines
          continue;
        }
      }

      // If status is still 'in_progress' after scan, check the last valid event's level
      if (status === 'in_progress' && lastValidEvent && lastValidEvent.level === 'error') {
        status = 'failed';
      }

      // Helper functions for PID mapping and status
      function buildScenarioPIDMapping(motherLines: string[]): Map<string, number> {
        const mapping = new Map<string, number>();
        for (const line of motherLines) {
          try {
            const event = JSON.parse(line);
            const message = event.message || '';
            const matches = message.match(/Spawned Scenario ([^ ]+) with PID (\d+)/);
            if (matches) {
              const [_, scenarioId, pidStr] = matches;
              mapping.set(scenarioId, parseInt(pidStr));
            }
          } catch (e) {
            continue;
          }
        }
        return mapping;
      }

      function getScenarioStatus(scenarioId: string, pidMapping: Map<string, number>): string {
        const pid = pidMapping.get(scenarioId);
        if (!pid) return 'Unknown';
        return terminatedPids.has(pid) ? 'Terminated' : 'Running';
      }

      // Build PID mapping from mother log
      const pidMapping = buildScenarioPIDMapping(motherLines);

      // Count scenario statuses
      const reportsDir = join(sessionDir, 'reports');
      const scenarioLogs = await readdir(logsDir);
      const reportFiles = await readdir(reportsDir);
      
      // Count scenarios by status
      let runningCount = 0;
      let terminatedCount = 0;
      let reportedCount = reportFiles.length;

      // Check each scenario's status using the PID mapping
      for (const logFile of scenarioLogs.filter(f => f.startsWith('scenario-'))) {
        const scenarioId = logFile.replace('scenario-', '').replace('.log', '');
        const status = getScenarioStatus(scenarioId, pidMapping);
        
        if (status === 'Terminated') {
          terminatedCount++;
        } else if (!reportFiles.includes(scenarioId + '.json')) {
          runningCount++;
        }
      }

      // Build the pulse
      let pulse = `=== Deebo Session Pulse: ${sessionId} ===\n`;
      pulse += `Timestamp: ${new Date().toISOString()}\n`;
      pulse += `Overall Status: ${status}\n`;
      pulse += `Session Duration: ${Math.floor(durationMs / 1000)}s\n\n`;

      pulse += `--- Mother Agent ---\n`;
      pulse += `Status: ${status === 'in_progress' ? 'working' : status}\n`;
      pulse += `Last Activity: ${lastValidEvent ? lastValidEvent.timestamp : 'N/A'}\n`;
      if (status === 'completed') {
        // Get projectId from session directory path
        const projectId = sessionDir.split('/memory-bank/')[1].split('/')[0];
        pulse += `Progress Log: ${join(DEEBO_ROOT, 'memory-bank', projectId, 'progress.md')}\n`;
      }

      // Update summary line to include terminated count
      pulse += `--- Scenario Agents (${scenarioLogs.filter(f => f.startsWith('scenario-')).length} Total: ${runningCount} Running, ${terminatedCount} Terminated, ${reportedCount} Reported) ---\n\n`;

      // For completed sessions, find and show solution
      if (status === 'completed') {
        // Display solution if found during scan
        if (solutionContent) {
          pulse += `MOTHER SOLUTION:\n`;
          pulse += `<<<<<<< SOLUTION\n`;
          pulse += solutionContent + '\n';
          pulse += `======= SOLUTION END >>>>>>>\n\n`;
        } else {
          pulse += `STATUS COMPLETE BUT NO SOLUTION TAG FOUND IN LOGS\n`;
          pulse += `Check the mother.log file for more details.\n\n`;
        }
      } else if (status === 'in_progress' || status === 'failed') {
        // For in-progress or failed, show last known stage or last message
        let stageMessage = 'No stage information found.';
        if (lastValidEvent) { // Use the last valid event captured during status scan
             stageMessage = lastValidEvent.message || JSON.stringify(lastValidEvent.data); // Show message or data
             if (lastValidEvent.message && lastValidEvent.message.includes('OODA:')) {
                 pulse += `Last Stage: ${lastValidEvent.message}\n\n`;
             } else {
                 pulse += `Last Log Message: ${stageMessage.substring(0, 100)}${stageMessage.length > 100 ? '...' : ''}\n\n`;
             }
        } else {
             pulse += `Last Stage: ${stageMessage}\n\n`;
        }

      }


      // Process reported scenarios
      for (const file of reportFiles) {
        const scenarioId = file.replace('.json', '');
        
        const scenarioLogPath = join(logsDir, `scenario-${scenarioId}.log`);
        let scenarioLog;
        try {
          scenarioLog = await readFile(scenarioLogPath, 'utf8');
        } catch (e) {
          continue; // Skip if log file doesn't exist
        }
        
        const scenarioLines = scenarioLog.split('\n').filter(Boolean);
        if (!scenarioLines.length) continue;

        // Get hypothesis - scan once
        let hypothesis = 'Unknown hypothesis';
        for (let i = 0; i < scenarioLines.length; i++) {
          try {
            const event = JSON.parse(scenarioLines[i]);
            if (event.data?.hypothesis) {
              hypothesis = event.data.hypothesis;
              break;
            }
          } catch (e) {
            continue;
          }
        }

        pulse += `* Scenario: ${scenarioId}\n`;
        pulse += `  Status: Reported\n`;

        if (status === 'completed') {
          // Show summary for completed scenarios in completed sessions
          try {
            const reportRaw = await readFile(join(reportsDir, `${scenarioId}.json`), 'utf8');
            const report = JSON.parse(reportRaw);
            
            // Extract key information from report
            const reportStr = typeof report === 'string' ? report : JSON.stringify(report, null, 2);
            const lines = reportStr.split('\n');
            
            // Find CONFIRMED status and INVESTIGATION section
            let confirmed = 'Unknown';
            let investigationLines: string[] = [];
            let inInvestigation = false;
            
            for (let i = 0; i < lines.length; i++) {
              const line = lines[i].trim();
              if (line.startsWith('CONFIRMED:')) {
                confirmed = line.split(':')[1].trim();
              }
              if (line === 'INVESTIGATION:') {
                inInvestigation = true;
                continue;
              }
              if (inInvestigation && line && !line.startsWith('CONCLUSION:')) {
                investigationLines.push(line);
              }
              if (line.startsWith('CONCLUSION:')) {
                break;
              }
            }
            
            pulse += `  Outcome Summary:\n`;
            pulse += `  <<<<<<< OUTCOME ${scenarioId}\n`;
            pulse += `  HYPOTHESIS: ${hypothesis}\n\n`;
            pulse += `  CONFIRMED: ${confirmed}\n\n`;
            if (investigationLines.length > 0) {
              pulse += `  INVESTIGATION:\n`;
              pulse += `  ${investigationLines.join('\n  ')}\n`;
            }
            pulse += `  ======= OUTCOME ${scenarioId} END >>>>>>>\n`;
          } catch (e) {
            const error = e as Error;
            pulse += `  Error reading report: ${error.message}\n`;
          }
        }

        pulse += `  (Full report: ${join(reportsDir, `${scenarioId}.json`)})\n\n`;
      }

      // Process unreported scenarios (either running or terminated without report)
      const unreportedScenarios = scenarioLogs
        .filter(f => f.startsWith('scenario-'))
        .filter(f => !reportFiles.includes(f.replace('scenario-', '').replace('.log', '.json')));
      
      for (const file of unreportedScenarios) {
        const scenarioId = file.replace('scenario-', '').replace('.log', '');
        
        let scenarioLog;
        try {
          scenarioLog = await readFile(join(logsDir, file), 'utf8');
        } catch (e) {
          continue; // Skip if log file doesn't exist
        }
        
        const scenarioLines = scenarioLog.split('\n').filter(Boolean);
        if (!scenarioLines.length) continue;

        // Get hypothesis and events from scenario log
        let hypothesis = 'Unknown hypothesis';
        let firstEvent, lastEvent;
        
        try {
          // Extract hypothesis and events
          for (const line of scenarioLines) {
            try {
              const event = JSON.parse(line);
              if (event.data?.hypothesis) {
                hypothesis = event.data.hypothesis;
              }
              if (!firstEvent) firstEvent = event;
              lastEvent = event;
            } catch (e) {
              continue;
            }
          }

          // Calculate runtime and add to pulse
          const runtime = Math.floor((Date.now() - new Date(firstEvent.timestamp).getTime()) / 1000);
          pulse += `* Scenario: ${scenarioId}\n`;
          pulse += `  Status: ${getScenarioStatus(scenarioId, pidMapping)}\n`;
          pulse += `  Hypothesis: "${hypothesis}"\n`;
          pulse += `  Runtime: ${runtime}s\n`;
          pulse += `  Latest Activity: ${lastEvent.message}\n`;
          pulse += `  (Log: ${join(logsDir, file)})\n\n`;
        } catch (e) {
          // Skip scenarios with invalid JSON
          continue;
        }
      }

      pulse += `--- End Session Pulse ---\n\n`;

if (status === 'completed' || status === 'failed') {
  pulse += `\n=======================================\n`;
  pulse += `Not the result you were looking for?\n`;
  pulse += `Start another session and guide Deebo with what you learned!\n`;
  pulse += `Need a refresher? Check out the Deebo GitHub:\n`;
  pulse += `https://github.com/snagasuri/deebo-prototype\n`;
  pulse += `=======================================\n`;
}

      return {
        content: [{ 
          type: "text",
          text: pulse
        }]
      };

    } catch (err) {
      return {
        content: [{ 
          type: "text",
          text: `Error generating pulse: ${err}`
        }]
      };
    }
  }
);

server.tool(
  "cancel",
  "Terminates all processes related to a debugging session. This will stop the mother agent and all scenario agents, releasing system resources. Use this when you have your solution or want to abandon the debugging process.",
  {
    sessionId: z.string().describe("The session ID returned by the start tool when the debugging session was initiated")
  },
  async ({ sessionId }, extra) => {
    // No need to sanitize ID when using the registry Map key
    const sessionEntry = processRegistry.get(sessionId);

    if (!sessionEntry) {
      return {
        content: [{
          type: "text",
          text: `Session ${sessionId} not found in registry. It might have already completed or failed.`
        }]
      };
    }

    const { motherController, scenarioPids } = sessionEntry;
    let killedScenarios = 0;
    let failedKills = 0;

    try {
      // 1. Signal the Mother agent to stop its loop cooperatively
      // console.log(`Signaling Mother Agent for session ${sessionId} to stop.`); // Removed informational log
      motherController.abort();

      // 2. Terminate any tracked Scenario agent processes
      // console.log(`Terminating ${scenarioPids.size} tracked Scenario Agents for session ${sessionId}.`); // Removed informational log
      for (const pid of scenarioPids) {
        try {
          // Use SIGTERM first for graceful shutdown
          process.kill(pid, 'SIGTERM');
          killedScenarios++;
          terminatedPids.add(pid); // Add to terminated set right away
          // console.log(`Sent SIGTERM to scenario PID ${pid}`); // Removed informational log
        } catch (err: any) {
          // Ignore errors if process is already gone (e.g., ESRCH)
          if (err.code !== 'ESRCH') {
            // console.warn(`Failed to send SIGTERM to scenario PID ${pid}: ${err.message}`); // Removed console.warn
            failedKills++;
          } else {
            // Process already gone
            terminatedPids.add(pid); // Still mark as terminated if process is already gone
          }
        }
      }

      // Optional: Add a short delay and SIGKILL survivors if needed.
      // For simplicity, we'll rely on SIGTERM for now.

      // 3. Clean up the registry entry *after* attempting kills
      processRegistry.delete(sessionId);
      // console.log(`Removed session ${sessionId} from process registry.`); // Removed informational log

      return {
          content: [{
            type: "text",
            text: `Cancellation request sent for session ${sessionId}:\n` +
                  `- Mother agent signaled to stop.\n` +
                  `- Targeted ${killedScenarios} scenario processes (includes already exited).\n` +
                  `- ${failedKills} termination signals failed (excluding already exited).`
          }]
        };

      } catch (err: any) {
        // Handle potential errors during the cancellation process itself
        const errorMessage = err.message || String(err);
        // console.error(`Error during cancellation for session ${sessionId}: ${errorMessage}`); // Removed console.error
        // Attempt to clean up registry even if cancellation had issues
        processRegistry.delete(sessionId); // Ensure cleanup
        return {
          content: [{
            type: "text",
            text: `Error during cancellation for session ${sessionId}: ${errorMessage}. Registry entry removed.`
          }]
        };
      }
    }
  );

// Register add_observation tool
server.tool(
  "add_observation",
  "Adds an external observation to an agent in the debugging session. This allows other tools or human insights to be incorporated into the ongoing investigation. Observations are logged and considered by the agent in subsequent reasoning steps.",
  {
    agentId: z.string(),
    observation: z.string(),
    sessionId: z.string()
  },
  async ({ agentId, observation, sessionId }, extra) => {
    try {
      // Get session directory
      const sessionDir = await findSessionDir(sessionId);
      if (!sessionDir) {
        throw new Error('Session not found');
      }

      // Get repoPath from agent log
      const logFile = join(sessionDir, 'logs', `${agentId}.log`);
      const agentLog = await readFile(logFile, 'utf8');
      const firstLine = agentLog.split('\n')[0];
      const firstEvent = JSON.parse(firstLine);
      const repoPath = firstEvent.data?.repoPath;

      if (!repoPath) {
        throw new Error('Could not find repoPath in agent log');
      }

      await writeObservation(repoPath, sessionId, agentId, observation);
      return {
        content: [{
          type: "text",
          text: "Observation logged"
        }]
      };
    } catch (err) {
      throw new Error(`Observation write failed: ${err instanceof Error ? err.message : String(err)}`);
    }
  }
);

// Connect transport
const transport = new StdioServerTransport();
await server.connect(transport);

=== src/util/mcp.ts ===

// src/util/mcp.ts
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { readFile, writeFile } from 'fs/promises';
import { join } from 'path';
import * as path from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// Map to track active connections
const activeConnections: Map<string, Promise<Client>> = new Map();

export async function connectMcpTool(name: string, toolName: string, sessionId: string, repoPath: string) {
  const rawConfig = JSON.parse(await readFile(join(DEEBO_ROOT, 'config', 'tools.json'), 'utf-8'));
  const def = rawConfig.tools[toolName];
  const memoryPath = join(DEEBO_ROOT, 'memory-bank', getProjectId(repoPath));
  const memoryRoot = join(DEEBO_ROOT, 'memory-bank');

  /* --- WINDOWS-ONLY PATCH ----------------------------------------- */
  if (process.platform === "win32" && toolName === "desktopCommander") {
    // Use the real *.cmd so the process owns stdin/stdout
    const cmdPath = path.join(process.env.DEEBO_NPM_BIN!, "desktop-commander.cmd");
    def.command = cmdPath;
    def.args = ["serve"];            // same behaviour as 'npx … serve'
  }
  /* ---------------------------------------------------------------- */

  // Substitute npx/uvx paths directly in the command
  let command = def.command
    .replace(/{npxPath}/g, process.env.DEEBO_NPX_PATH!)
    .replace(/{uvxPath}/g, process.env.DEEBO_UVX_PATH!);
  
  // Replace placeholders in all args
  let args = def.args.map((arg: string) =>
    arg
      .replace(/{repoPath}/g, repoPath)
      .replace(/{memoryPath}/g, memoryPath)
      .replace(/{memoryRoot}/g, memoryRoot)
  );

  // No shell: spawn the .cmd/binary directly on all platforms
  const options = {};

  const transport = new StdioClientTransport({ command, args, ...options });
  const client = new Client({ name, version: '1.0.0' }, { capabilities: { tools: true } });
  await client.connect(transport);
  return client;
}

export async function connectRequiredTools(agentName: string, sessionId: string, repoPath: string): Promise<{
  gitClient: Client;
  filesystemClient: Client;
}> {
  const [gitClient, filesystemClient] = await Promise.all([
    connectMcpTool(`${agentName}-git`, 'git-mcp', sessionId, repoPath),
    // Switch from "filesystem-mcp" to "desktop-commander"
    connectMcpTool(`${agentName}-desktop-commander`, 'desktopCommander', sessionId, repoPath)
  ]);

  return { gitClient, filesystemClient };
}

=== config/tools.json ===

{
  "tools": {
    "desktopCommander": {
      "command": "{npxPath}",
      "args": [
        "@wonderwhy-er/desktop-commander"
      ]
    },
    "git-mcp": {
      "command": "{uvxPath}",
      "args": [
        "mcp-server-git",
        "--repository",
        "{repoPath}"
      ]
    }
  }
}
=== src/util/sanitize.ts ===

// src/util/sanitize.ts
import { createHash } from 'crypto';

export function getProjectId(repoPath: string): string {
  const hash = createHash('sha256').update(repoPath).digest('hex');
  return hash.slice(0, 12); // use first 12 characters
}
=== src/util/reports.ts ===

import { mkdir, writeFile } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// src/util/reports.ts
//we changed it to text to make check tool work better then changed it back to json
// after removing validation.ts which was blocking access to memory bank files 
// but really inelegantly so i took it out but i might have not reverted all the 
// changes so there's probably that if you're still getting bugs
export async function writeReport(repoPath: string, sessionId: string, scenarioId: string, report: string) {
    const projectId = getProjectId(repoPath);
    const reportDir = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'reports');
    await mkdir(reportDir, { recursive: true });
    const reportPath = join(reportDir, `${scenarioId}.json`);
    await writeFile(reportPath, JSON.stringify(report, null, 2));
}

=== src/util/branch-manager.ts ===

// src/util/branch-manager.ts
import { simpleGit } from 'simple-git';

// note: second parameter is `scenarioId`
export async function createScenarioBranch(repoPath: string, scenarioId: string): Promise<string> {
  const git = simpleGit(repoPath);
  const branchName = `debug-${scenarioId}`;  // e.g. debug-session-1745287764331-0
  await git.checkoutLocalBranch(branchName);
  return branchName;
}
=== src/util/agent-utils.ts ===

import { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import { GoogleGenerativeAI, Content, Part } from "@google/generative-ai";
import Anthropic from "@anthropic-ai/sdk"; // Import the default export
import { MessageParam } from "@anthropic-ai/sdk/resources/messages.mjs"; // Import the specific type
import OpenAI from "openai";
import { ChatModel } from 'openai/resources';

// Define an interface for the configuration passed from agents
interface LlmConfig {
  provider?: string;
  model?: string;
  maxTokens?: number;
  apiKey?: string; // Generic key, primarily used for OpenRouter for backward compatibility
  openrouterApiKey?: string; // Alias for apiKey, prefer this for new code
  baseURL?: string; // For OpenAI-compatible APIs
  openaiApiKey?: string; // For OpenAI and compatible providers
  geminiApiKey?: string;
  anthropicApiKey?: string;
}

/**
 * Generates the mother agent's system prompt with the given parameters
 */
export function getMotherAgentPrompt(useMemoryBank: boolean, memoryBankPath: string): string {
  return `You are the mother agent in an OODA loop debugging investigation. Your core mission:

1. INVESTIGATE and HYPOTHESIZE aggressively
2. Don't wait for perfect information
3. Generate hypotheses even if you're uncertain

KEY DIRECTIVES:
- Always generate at least one hypothesis within your first 2-3 responses
- Use <hypothesis>Your hypothesis here</hypothesis> liberally
- Better to spawn 5 wrong scenario agents than miss the right one
- If you see an error message, immediately form hypotheses about its causes
- Don't wait for full context - start with what you have
- AVOID REDUNDANT HYPOTHESES - read scenario reports to learn what's been tried
- Pass what failed to scenarios via context argument so they don't waste time
- Take notes! You're a scientist mother (think Dr. Akagi), not a robot. Be creative and curious.

SOLUTION CONFIDENCE:
Only use <solution> tags when you are at least 96% confident in the solution.
If your confidence is lower:
- Create your own branch to test it
- Keep investigating (you have the same tools as scenarios)
- Generate new hypotheses if needed
Solution tags = "I am at least 96% confident this works"
When you've found a solution or determined none exists, wrap it in solution tags:
<solution>Your final conclusion and solution here</solution>
${useMemoryBank ? `
MEMORY BANK INVESTIGATION AIDS:
The memory bank at ${memoryBankPath} contains two key files to help your investigation:

1. activeContext.md - Your live investigation notebook:
- READ THIS FIRST when starting an investigation using ${memoryBankPath}/activeContext.md
- Contains your previous debugging notes and observations
- Shows which approaches were promising vs dead ends
- Records important error patterns you've noticed
- Use this to avoid repeating failed approaches
- Read this to understand which parts of the code were already examined
- To edit, use read_file to get the latest state, then write a targeted diff using edit_file instead of write_file to avoid overwriting

2. progress.md - The full debugging history (access at ${memoryBankPath}/progress.md):
- Contains complete records of all debug sessions
- Shows which hypotheses were tried and their outcomes
- Lists all scenarios that were run and their results
- Use this to see if similar bugs were fixed before

Use these files to:
- Build on previous investigation progress
- Spot patterns in failing scenarios
- Generate better hypotheses based on what's worked/failed
- Provide relevant context to scenario agents
- Track the evolution of your debugging approach
- Take notes! You're a scientist mother (think Dr. Akagi), not a robot. Be creative and curious.

IMPORTANT: Always use ${memoryBankPath} as the absolute path for memory bank files. Never use relative paths.
` : ''}

TOOL USAGE:
Always use this exact format for tools:
<use_mcp_tool>
  <server_name>git-mcp</server_name>
  <tool_name>git_status</tool_name>
  <arguments>
    {
      "repo_path": "/path/to/repo"
    }
  </arguments>
</use_mcp_tool>

Available Tools:
git-mcp (use for ALL git operations):
- git_status: Show working tree status
  Example: { "repo_path": "/path/to/repo" }
- git_diff_unstaged: Show changes in working directory not yet staged
  Example: { "repo_path": "/path/to/repo" }
- git_diff_staged: Show changes that are staged for commit
  Example: { "repo_path": "/path/to/repo" }
- git_diff: Compare current state with a branch or commit
  Example: { "repo_path": "/path/to/repo", "target": "main" }
- git_add: Stage file changes
  Example: { "repo_path": "/path/to/repo", "files": ["file1.ts", "file2.ts"] }
- git_commit: Commit staged changes
  Example: { "repo_path": "/path/to/repo", "message": "commit message" }
- git_reset: Unstage all changes
  Example: { "repo_path": "/path/to/repo" }
- git_log: Show recent commit history
  Example: { "repo_path": "/path/to/repo" }
- git_checkout: Switch to a different branch
  Example: { "repo_path": "/path/to/repo", "branch_name": "debug-123" }
- git_show: Show contents of a specific commit
  Example: { "repo_path": "/path/to/repo", "revision": "HEAD" }

desktop-commander (use ONLY for non-git operations):

Terminal Tools:
- execute_command: Run terminal commands with timeout
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>execute_command</tool_name>
    <arguments>
      {
        "command": "npm run build",
        "timeout_ms": 5000
      }
    </arguments>
  </use_mcp_tool>

- read_output: Get output from running commands
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_output</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- force_terminate: Stop running command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>force_terminate</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- list_sessions: View active command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_sessions</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- list_processes: List system processes
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_processes</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- kill_process: Terminate processes by PID
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>kill_process</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- block_command: Block a command from execution
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>block_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

- unblock_command: Unblock a command
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>unblock_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

Filesystem Tools:
- read_file: Read file contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_file</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}/activeContext.md"
      }
    </arguments>
  </use_mcp_tool>

- read_multiple_files: Read multiple files at once
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_multiple_files</tool_name>
    <arguments>
      {
        "paths": ["file1.ts", "file2.ts"]
      }
    </arguments>
  </use_mcp_tool>

- write_file: Write content to files
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>write_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "content": "console.log('hello');"
      }
    </arguments>
  </use_mcp_tool>

- edit_file: Apply surgical text replacements
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>edit_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "diff": "<<<<<<< SEARCH\nold code\n=======\nnew code\n>>>>>>> REPLACE"
      }
    </arguments>
  </use_mcp_tool>

- list_directory: List directory contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_directory</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}"
      }
    </arguments>
  </use_mcp_tool>

- search_files: Search files with pattern
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_files</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}",
        "pattern": "error",
        "file_pattern": "*.ts"
      }
    </arguments>
  </use_mcp_tool>

- create_directory: Create a new directory
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>create_directory</tool_name>
    <arguments>
      {
        "path": "new-dir"
      }
    </arguments>
  </use_mcp_tool>

- move_file: Move or rename a file
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>move_file</tool_name>
    <arguments>
      {
        "source": "old.ts",
        "destination": "new.ts"
      }
    </arguments>
  </use_mcp_tool>

- get_file_info: Get file metadata
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>get_file_info</tool_name>
    <arguments>
      {
        "path": "file.ts"
      }
    </arguments>
  </use_mcp_tool>

- search_code: Recursive code search
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_code</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}",
        "pattern": "function",
        "filePattern": "*.ts",
        "contextLines": 2,
        "ignoreCase": true
      }
    </arguments>
  </use_mcp_tool>

IMPORTANT MEMORY BANK WARNINGS:
- DO NOT use write_file on memory bank files - use filesystem-mcp edit_file instead
- Only edit memory bank through edit_file to avoid overwrites
- Always use ${memoryBankPath} as absolute path for memory bank files`;
}



/**
 * Generates the scenario agent's system prompt with the given parameters
 */
export function getScenarioAgentPrompt(args: {
  branch: string;
  hypothesis: string;
  context: string;
  repoPath: string;
}): string {
  return `You are a scenario agent investigating a bug based on a specific hypothesis.
A dedicated Git branch '${args.branch}' has been created for your investigation.

Your hypothesis: "${args.hypothesis}"
Your job is to either validate the hypothesis, falsify it, or propose alternative directions if stuck. You do not need to fix the entire bug — your focus is the truth of the SPECIFIC hypothesis you are assigned to.
That being said, don't be too hasty to report a conclusion. If you see something potentially useful/interesting, investigate it further. Debugging is a complicated, nonlinear process, and subtle clues could be useful.
IMPORTANT:
- READ THE CONTEXT CAREFULLY: "${args.context}"
- This contains what approaches have failed and why
- Don't waste time repeating failed attempts
- These are instructions, not suggestions. Do not retry any approach listed here as 'already attempted'.
- Mother agent is counting on you to explore NEW approaches
- When you're reasonably confident, wrap up with <report> tags

TOOL USAGE:
Always use this exact format for tools:
<use_mcp_tool>
  <server_name>git-mcp</server_name>
  <tool_name>git_status</tool_name>
  <arguments>
    {
      "repo_path": "${args.repoPath}"
    }
  </arguments>
</use_mcp_tool>

Available Tools:
git-mcp (use for ALL git operations):
- git_status: Show working tree status
  Example: { "repo_path": "${args.repoPath}" }
- git_diff_unstaged: Show changes in working directory not yet staged
  Example: { "repo_path": "${args.repoPath}" }
- git_diff_staged: Show changes that are staged for commit
  Example: { "repo_path": "${args.repoPath}" }
- git_diff: Compare current state with a branch or commit
  Example: { "repo_path": "${args.repoPath}", "target": "main" }
- git_add: Stage file changes
  Example: { "repo_path": "${args.repoPath}", "files": ["file1.ts", "file2.ts"] }
- git_commit: Commit staged changes
  Example: { "repo_path": "${args.repoPath}", "message": "commit message" }
- git_reset: Unstage all changes
  Example: { "repo_path": "${args.repoPath}" }
- git_log: Show recent commit history
  Example: { "repo_path": "${args.repoPath}" }
- git_show: Show contents of a specific commit
  Example: { "repo_path": "${args.repoPath}", "revision": "HEAD" }

desktop-commander (use ONLY for non-git operations):

Terminal Tools:
- execute_command: Run terminal commands with timeout
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>execute_command</tool_name>
    <arguments>
      {
        "command": "npm run build",
        "timeout_ms": 5000
      }
    </arguments>
  </use_mcp_tool>

- read_output: Get output from running commands
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_output</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- force_terminate: Stop running command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>force_terminate</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- list_sessions: View active command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_sessions</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- list_processes: List system processes
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_processes</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- kill_process: Terminate processes by PID
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>kill_process</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- block_command: Block a command from execution
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>block_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

- unblock_command: Unblock a command
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>unblock_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

Filesystem Tools:
- read_file: Read file contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_file</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}/file.ts"
      }
    </arguments>
  </use_mcp_tool>

- read_multiple_files: Read multiple files at once
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_multiple_files</tool_name>
    <arguments>
      {
        "paths": ["file1.ts", "file2.ts"]
      }
    </arguments>
  </use_mcp_tool>

- write_file: Write content to files
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>write_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "content": "console.log('hello');"
      }
    </arguments>
  </use_mcp_tool>

- edit_file: Apply surgical text replacements
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>edit_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "diff": "<<<<<<< SEARCH\nold code\n=======\nnew code\n>>>>>>> REPLACE"
      }
    </arguments>
  </use_mcp_tool>

- list_directory: List directory contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_directory</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}"
      }
    </arguments>
  </use_mcp_tool>

- search_files: Search files with pattern
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_files</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}",
        "pattern": "error",
        "file_pattern": "*.ts"
      }
    </arguments>
  </use_mcp_tool>

- create_directory: Create a new directory
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>create_directory</tool_name>
    <arguments>
      {
        "path": "new-dir"
      }
    </arguments>
  </use_mcp_tool>

- move_file: Move or rename a file
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>move_file</tool_name>
    <arguments>
      {
        "source": "old.ts",
        "destination": "new.ts"
      }
    </arguments>
  </use_mcp_tool>

- get_file_info: Get file metadata
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>get_file_info</tool_name>
    <arguments>
      {
        "path": "file.ts"
      }
    </arguments>
  </use_mcp_tool>

- search_code: Recursive code search
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_code</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}",
        "pattern": "function",
        "filePattern": "*.ts",
        "contextLines": 2,
        "ignoreCase": true
      }
    </arguments>
  </use_mcp_tool>

REPORT FORMAT:
When you've completed your investigation, use:
<report>
HYPOTHESIS: [Original hypothesis]
CONFIRMED: [Yes/No/Partially]
INVESTIGATION:
[Briefly explain what context you took into account and how this differed]
[Summary of what you tried]
[Key findings]
[Why this confirms/refutes hypothesis]

CHANGES MADE:
[List any file changes]
[Why each change was needed]

CONFIDENCE: [High/Medium/Low]
[Explanation of confidence level]
</report>`;
}


export async function callLlm(
  messages: ChatCompletionMessageParam[],
  config: LlmConfig
): Promise<string> {
  const {
    provider,
    model,
    maxTokens = 4096,
    apiKey,
    openrouterApiKey,
    baseURL,
    openaiApiKey,
    geminiApiKey,
    anthropicApiKey
  } = config;

  const lowerCaseProvider = provider?.toLowerCase();

  if (lowerCaseProvider === 'openai') {
    if (!openaiApiKey) throw new Error("API key is required for 'openai' provider.");
    if (!baseURL) throw new Error("Base URL is required for 'openai' provider.");
    const openai = new OpenAI({
      apiKey: openaiApiKey,
      baseURL: baseURL,
    });
    const completion = await openai.chat.completions.create({
      model: (model || 'gpt-4o') as ChatModel,
      max_tokens: maxTokens,
      messages
    });
    return completion.choices?.[0]?.message?.content || '';
  }

  if (lowerCaseProvider === 'openrouter') {
    if (!openrouterApiKey && !apiKey) throw new Error("OpenRouter API key is required for 'openrouter' provider.");
    const openai = new OpenAI({
      apiKey: openrouterApiKey || apiKey, // Use new name if available, fall back to old name
      baseURL: 'https://openrouter.ai/api/v1',
    });
    const completion = await openai.chat.completions.create({
      model: (model || 'openai/gpt-4o') as ChatModel, // Use provided model or default
      max_tokens: maxTokens,
      messages
    });
    return completion.choices?.[0]?.message?.content || '';
  }

  if (lowerCaseProvider === 'gemini') {
    if (!geminiApiKey) throw new Error("Gemini API key is required for 'gemini' provider.");
    const gemini = new GoogleGenerativeAI(geminiApiKey);
    const model_name = model || 'gemini-1.5-pro'; // Use provided model or default
    const genModel = gemini.getGenerativeModel({ model: model_name });

    // Correctly map messages to Gemini's Content[] format
    const geminiHistory: Content[] = messages.map(m => ({
      role: m.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: m.content as string }] as Part[] // Ensure parts is an array of Part
    }));

    const result = await genModel.generateContent({
      contents: geminiHistory,
      generationConfig: {
        maxOutputTokens: maxTokens
      }
    });
    const response = await result.response;
    return response.text() || '';
  }

  if (lowerCaseProvider === 'anthropic') {
    if (!anthropicApiKey) throw new Error("Anthropic API key is required for 'anthropic' provider.");
    const anthropic = new Anthropic({ apiKey: anthropicApiKey });
    // Correctly map messages to Anthropic's MessageParam[] format with explicit roles
    const anthropicMessages: MessageParam[] = messages.map(m => ({
      role: (m.role === 'assistant' ? 'assistant' : 'user') as 'user' | 'assistant',
      content: m.content as string
    }));

    const raw = await anthropic.messages.create({
      model: (model || 'claude-3-sonnet-20240229') as any, // Use provided model or default
      max_tokens: maxTokens,
      messages: anthropicMessages,
    });
    // Check if the first content block is a TextBlock before accessing text
    const firstContent = raw.content[0];
    return firstContent && firstContent.type === 'text' ? firstContent.text : '';
  }

  throw new Error(`Unsupported provider '${lowerCaseProvider}'. Set LLM_PROVIDER env var to 'openai', 'openrouter', 'gemini', or 'anthropic'`);
}

=== src/util/logger.ts ===

import { writeFile, mkdir } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// Write logs to memory bank structure
export async function log(sessionId: string, name: string, level: string, message: string, data?: any) {
  const entry = JSON.stringify({
    timestamp: new Date().toISOString(),
    agent: name,
    level,
    message,
    data
  }) + '\n';

  // Data will be written to memory-bank/projectId/sessions/sessionId/logs/agentName.log
  const projectId = getProjectId(data?.repoPath);
  if (projectId) {
    const logPath = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'logs', `${name}.log`);
    await writeFile(logPath, entry, { flag: 'a' });
  }
}

// Simple console logging
export function consoleLog(level: string, message: string, data?: any) {
  console.log(`[${level}] ${message}`, data || '');
}

=== src/util/membank.ts ===

// src/util/membank.js
import { join } from 'path';
import { writeFile } from 'fs/promises';
import { DEEBO_ROOT } from '../index.js';

export async function updateMemoryBank(projectId: string, content: string, file: 'activeContext' | 'progress'): Promise<void> {
  const path = join(DEEBO_ROOT, 'memory-bank', projectId, `${file}.md`);
  await writeFile(path, '\n' + content, { flag: 'a' });
}
=== src/util/observations.ts ===

import { writeFile, mkdir, readFile } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

export async function getAgentObservations(repoPath: string, sessionId: string, agentId: string): Promise<string[]> {
  const projectId = getProjectId(repoPath);
  const obsPath = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'observations', `${agentId}.log`);
  
  try {
    const content = await readFile(obsPath, 'utf8');
    return content
      .split('\n')
      .filter(Boolean)
      .map((line: string) => JSON.parse(line).observation);
  } catch {
    return []; // No observations yet
  }
}

export async function writeObservation(repoPath: string, sessionId: string, agentId: string, observation: string) {
  const projectId = getProjectId(repoPath);
  const obsDir = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'observations');
  await mkdir(obsDir, { recursive: true });
  
  const entry = JSON.stringify({
    timestamp: new Date().toISOString(),
    observation
  }) + '\n';
  
  await writeFile(join(obsDir, `${agentId}.log`), entry, { flag: 'a' });
}

=== src/mother-agent.ts ===

// src/mother-agent.ts
/**
 * 📌 Why this is the best version:
    • ✅ Keeps full message history without resetting
    • ✅ Supports multiple tool calls per Claude response
    • ✅ Spawns scenarios from multiple hypotheses
    • ✅ Never throws on malformed XML, logs gently instead
    • ✅ Doesn't force memory bank writes — Mother can directly choose via filesystem-mcp
    • ✅ Maintains Deebo's spirit: autonomy, freedom to fail, and graceful continuation
    • ✅ FIXED: Processes tool calls before hypotheses from the same LLM turn.
 */

    import { spawn } from 'child_process';
    import { join } from 'path';
    import { getAgentObservations } from './util/observations.js';
    import { log } from './util/logger.js';
    import { connectRequiredTools } from './util/mcp.js';
    import { DEEBO_ROOT } from './index.js';
    import { updateMemoryBank } from './util/membank.js';
    import { getProjectId } from './util/sanitize.js';
    import { ChatCompletionMessageParam } from 'openai/resources/chat/completions'; // Keep structure type
    import { createScenarioBranch } from './util/branch-manager.js';
    import { callLlm, getMotherAgentPrompt } from './util/agent-utils.js';
    
    const MAX_RUNTIME = 60 * 60 * 1000; // 60 minutes
    const SCENARIO_TIMEOUT = 5 * 60 * 1000;
    const useMemoryBank = process.env.USE_MEMORY_BANK === 'true';
    
    // Mother agent main loop
    export async function runMotherAgent(
      sessionId: string,
      error: string,
      context: string,
      language: string,
      filePath: string,
      repoPath: string,
      signal: AbortSignal, // Added: Cancellation signal
      scenarioPids: Set<number> // Added: Set to track scenario PIDs
    ) {
      await log(sessionId, 'mother', 'info', 'Mother agent started', { repoPath });
      const projectId = getProjectId(repoPath);
      let scenarioCounter = 0; // Simple counter for unique scenario IDs within the session
      const startTime = Date.now();
      const memoryBankPath = join(DEEBO_ROOT, 'memory-bank', projectId);
      let lastObservationCheck = 0; // Removed unused variable
    
      try {
        // OBSERVE: Setup tools and LLM Client
        await log(sessionId, 'mother', 'info', 'OODA: observe', { repoPath });
        const { gitClient, filesystemClient } = await connectRequiredTools('mother', sessionId, repoPath);
    
        // Read LLM configuration from environment variables
        const motherProvider = process.env.MOTHER_HOST;
        const motherModel = process.env.MOTHER_MODEL;
        const openrouterApiKey = process.env.OPENROUTER_API_KEY;
        const openaiApiKey = process.env.OPENAI_API_KEY;
        const openaiBaseUrl = process.env.OPENAI_BASE_URL;
        const geminiApiKey = process.env.GEMINI_API_KEY;
        const anthropicApiKey = process.env.ANTHROPIC_API_KEY;
    
        // Create the config object to pass to callLlm
        const llmConfig = {
          provider: motherProvider,
          model: motherModel,
          apiKey: openrouterApiKey, // Keep for backward compatibility/other uses
          openrouterApiKey: openrouterApiKey,
          openaiApiKey: openaiApiKey,
          baseURL: openaiBaseUrl,
          geminiApiKey: geminiApiKey,
          anthropicApiKey: anthropicApiKey
        };
    
        // Initial conversation context
        const messages: ChatCompletionMessageParam[] = [{
          role: 'assistant',
          content: getMotherAgentPrompt(useMemoryBank, memoryBankPath)
        }, {
          role: 'user',
          content: `Error: ${error}
        Context: ${context}
        Language: ${language}
        File: ${filePath}
        Repo: ${repoPath}
        Session: ${sessionId}
        Project: ${projectId}
        ${useMemoryBank ? '\nPrevious debugging attempts and context are available in the memory-bank directory if needed.' : ''}
    
        IMPORTANT: Generate your first hypothesis within 2-3 responses. Don't wait for perfect information.`
        }];
    
        // Check for initial observations
        let observations = await getAgentObservations(repoPath, sessionId, 'mother');
        if (observations.length > 0) {
          messages.push(...observations.map(obs => ({
            role: 'user' as const,
            content: `Scientific observation: ${obs}`
          })));
        }
    
        // Initial LLM call
        await log(sessionId, 'mother', 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath });
        let replyText = await callLlm(messages, llmConfig);
        if (!replyText) {
          // Handle initial LLM failure more gracefully
          const initFailMsg = 'Initial LLM call returned empty or malformed response. Cannot proceed.';
          await log(sessionId, 'mother', 'error', initFailMsg, { provider: llmConfig.provider, model: llmConfig.model, repoPath });
          throw new Error(initFailMsg); // Throw to be caught by outer handler
        } else {
          // Add the valid response to messages history
          messages.push({ role: 'assistant', content: replyText });
          await log(sessionId, 'mother', 'debug', 'Received from LLM', { response: { content: replyText }, repoPath });
        }
    
        // ORIENT: Begin investigation loop
        await log(sessionId, 'mother', 'info', 'OODA: orient', { repoPath });
    
        // Loop while the last reply exists, doesn't contain a valid solution, AND cancellation hasn't been requested
        while (replyText && !(replyText.includes('<solution>') && replyText.match(/<solution>([\s\S]*?)<\/solution>/)?.[1]?.trim()) && !signal.aborted) {
          if (Date.now() - startTime > MAX_RUNTIME) {
            await log(sessionId, 'mother', 'warn', 'Investigation exceeded maximum runtime', { repoPath });
            throw new Error('Investigation exceeded maximum runtime');
          }
    
          // Check for cancellation signal before processing response
          if (signal.aborted) {
            await log(sessionId, 'mother', 'info', 'Cancellation signal received, stopping loop.', { repoPath });
            break; // Exit loop if cancelled
          }
    
          // Use the latest replyText from the end of the previous loop iteration (or the initial call)
          const responseText = replyText;
    
          // --- Check for Tools and Hypotheses ---
          const toolCalls = responseText.match(/<use_mcp_tool>[\s\S]*?<\/use_mcp_tool>/g) || [];
          const containsHypothesis = responseText.includes('<hypothesis>'); // Check for hypothesis presence
    
          let executeToolsThisTurn = false;
          let processHypothesesThisTurn = false;
    
          if (toolCalls.length > 0 && containsHypothesis) {
              // LLM included both - prioritize executing tools, ignore hypotheses this turn
              messages.push({
                  role: 'user',
                  content: `Instructions conflict: You provided tool calls and hypotheses in the same message. I will execute the tool calls now. Please provide hypotheses ONLY after analyzing the tool results in the next turn.`
              });
              executeToolsThisTurn = true; // Signal to execute tools below
              // DO NOT set processHypothesesThisTurn = true
              await log(sessionId, 'mother', 'warn', 'LLM provided tools and hypotheses simultaneously. Executing tools, ignoring hypotheses for this turn.', { repoPath });
    
          } else if (containsHypothesis) {
              // Only hypotheses found - process them
              processHypothesesThisTurn = true; // Signal to process hypotheses below
              executeToolsThisTurn = false; // Ensure tools aren't run if none were requested
    
          } else if (toolCalls.length > 0) {
               // Only tool calls found - execute them
               executeToolsThisTurn = true; // Signal to execute tools below
               processHypothesesThisTurn = false; // Ensure hypotheses aren't processed
          }
          // If neither tools nor hypotheses found, the loop continues to the next LLM call
    
    
          // --- Execute Tools if Flagged ---
          if (executeToolsThisTurn) {
              await log(sessionId, 'mother', 'debug', `Executing ${toolCalls.length} tool calls.`, { repoPath });
              const parsedCalls = toolCalls.map((tc: string) => {
                // Use try-catch for robust parsing
                try {
                  const serverNameMatch = tc.match(/<server_name>(.*?)<\/server_name>/);
                  if (!serverNameMatch || !serverNameMatch[1]) throw new Error('Missing server_name');
                  const serverName = serverNameMatch[1].trim(); // Trim whitespace
                  const server = serverName === 'git-mcp' ? gitClient! : filesystemClient!;
                  if (!server) throw new Error(`Invalid server_name: ${serverName}`);
    
                  const toolMatch = tc.match(/<tool_name>(.*?)<\/tool_name>/);
                  if (!toolMatch || !toolMatch[1]) throw new Error('Missing tool_name');
                  const tool = toolMatch[1].trim();
    
                  const argsMatch = tc.match(/<arguments>([\s\S]*?)<\/arguments>/); // Use [\s\S]*? for multiline args
                  if (!argsMatch || !argsMatch[1]) throw new Error('Missing arguments block');
                  const argsJson = argsMatch[1].trim();
                  if (!argsJson) throw new Error('Empty arguments block');
                  const args = JSON.parse(argsJson);
    
                  return { server, tool, args };
                } catch (err) {
                  log(sessionId, 'mother', 'error', `Failed to parse tool call: ${err instanceof Error ? err.message : String(err)}`, { toolCall: tc, repoPath });
                  return { error: err instanceof Error ? err.message : String(err) };
                }
              });
    
              // Process each parsed call
              for (const parsed of parsedCalls) {
                if ('error' in parsed) {
                  messages.push({
                    role: 'user',
                    content: `One of your tool calls was malformed and skipped. Error: ${parsed.error}`
                  });
                  continue; // Skip this malformed call
                }
    
                try {
                  await log(sessionId, 'mother', 'debug', `Executing tool: ${parsed.tool}`, { args: parsed.args, repoPath });
                  const result = await parsed.server.callTool({ name: parsed.tool, arguments: parsed.args });
                  messages.push({
                    role: 'user',
                    content: JSON.stringify(result) // Add tool result to history
                  });
                  await log(sessionId, 'mother', 'debug', `Tool result for ${parsed.tool}`, { result: result, repoPath });
                } catch (err) {
                  const errorMsg = `Tool call failed for '${parsed.tool}': ${err instanceof Error ? err.message : String(err)}`;
                  messages.push({
                    role: 'user',
                    content: errorMsg // Add tool error to history
                  });
                  await log(sessionId, 'mother', 'error', `Tool call execution failed: ${parsed.tool}`, { error: err instanceof Error ? err.message : String(err), repoPath });
                }
              }
              await log(sessionId, 'mother', 'debug', 'Finished executing tools for this turn.', { repoPath });
          } // End of tool execution block
    
    
          // --- Process Hypotheses and Spawn Scenarios if Flagged ---
          if (processHypothesesThisTurn) { // Use the flag here
            await log(sessionId, 'mother', 'debug', 'Processing hypotheses and spawning scenarios.', { repoPath });
            const hypotheses = [...responseText.matchAll(/<hypothesis>([\s\S]*?)<\/hypothesis>/g)].map(match => match[1].trim());
    
            if (hypotheses.length > 0) {
                 if (useMemoryBank) {
                   // Log hypotheses to memory bank (consider making this async and not awaiting if performance is key)
                   await updateMemoryBank(projectId, `==================
    AUTOMATED HYPOTHESIS RECORD
    Timestamp: ${new Date().toISOString()}
    Error: ${error || 'No error provided'}
    
    ${hypotheses.map(h => `<hypothesis>${h}</hypothesis>`).join('\n\n')}
    
    Context provided by LLM:
    ${responseText}
    ==================
    `, 'activeContext').catch(err => log(sessionId, 'mother', 'error', 'Failed to update memory bank hypothesis record', { error: err }));
                 }
    
                 const scenarioPromises = hypotheses.map(async (hypothesis: string) => {
                   const scenarioId = `${sessionId}-${scenarioCounter++}`; // Use counter for unique ID
    
                   // Create branch first
                   const branchName = await createScenarioBranch(repoPath, scenarioId);
    
                   const scenarioArgs = [ // Define args for spawn
                     join(DEEBO_ROOT, 'build/scenario-agent.js'),
                     '--id', scenarioId,
                     '--session', sessionId,
                     '--error', error,
                     '--context', context, // Pass original context or maybe updated? Check requirement.
                     '--hypothesis', hypothesis,
                     '--language', language,
                     '--file', filePath || '',
                     '--repo', repoPath,
                     '--branch', branchName
                   ];
    
                   const child = spawn('node', scenarioArgs, {
                      cwd: repoPath,
                      env: { ...process.env }
                   });
                   let output = '';
                   const scenarioPid = child.pid; // Capture PID early
    
                   if (scenarioPid) {
                     scenarioPids.add(scenarioPid);
                     await log(sessionId, 'mother', 'info', `Spawned Scenario ${scenarioId} with PID ${scenarioPid}`, { repoPath, hypothesis, args: scenarioArgs });
                   } else {
                     await log(sessionId, 'mother', 'warn', `Spawned Scenario ${scenarioId} but PID was unavailable`, { repoPath, hypothesis, args: scenarioArgs });
                   }
    
                   child.stdout.on('data', data => output += data);
                   child.stderr.on('data', data => output += data); // Capture stderr too
    
                   return new Promise<string>((resolve) => {
                     let resolved = false;
    
                     const cleanupAndResolve = (exitInfo: string) => {
                       if (resolved) return;
                       resolved = true;
                       if (scenarioPid) {
                         scenarioPids.delete(scenarioPid);
                         log(sessionId, 'mother', 'debug', `Removed scenario PID ${scenarioPid} from registry`, { repoPath });
                       }
                       output += `\n${exitInfo}`; // Append exit info to the captured output
                       resolve(output); // Resolve with the full output + exit info
                     };
    
                     child.on('exit', (code, signal) => {
                       cleanupAndResolve(`Scenario ${scenarioId} (PID: ${scenarioPid ?? 'N/A'}) exited with code ${code}, signal ${signal}`);
                     });
    
                     child.on('error', err => {
                       // Handle spawn errors specifically
                       const spawnErrorMsg = `Scenario ${scenarioId} (PID: ${scenarioPid ?? 'N/A'}) process spawn error: ${err.message}`;
                       output += `\n${spawnErrorMsg}`; // Add spawn error to output
                       cleanupAndResolve(spawnErrorMsg); // Resolve immediately
                     });
    
                      // Capture stream-level errors (don't resolve promise, just log)
                      child.stdout.on('error', err => { output += `\nScenario ${scenarioId} Stdout error: ${err.message}`; });
                      child.stderr.on('error', err => { output += `\nScenario ${scenarioId} Stderr error: ${err.message}`; });
    
    
                     const timeoutHandle = setTimeout(() => {
                       if (!resolved) {
                         log(sessionId, 'mother', 'warn', `Scenario ${scenarioId} (PID: ${scenarioPid}) timed out after ${SCENARIO_TIMEOUT / 1000}s. Killing...`, { repoPath });
                         child.kill('SIGTERM'); // Attempt graceful termination first
                         // Give it a moment, then force kill if needed
                         setTimeout(() => {
                             if (!resolved) {
                                 child.kill('SIGKILL');
                                 cleanupAndResolve(`Scenario ${scenarioId} (PID: ${scenarioPid}) timed out and was force killed.`);
                             }
                         }, 2000); // Wait 2s before SIGKILL
                       }
                     }, SCENARIO_TIMEOUT);
    
                     // Ensure timeout is cleared if process exits/errors cleanly
                     child.on('exit', () => clearTimeout(timeoutHandle));
                     child.on('error', () => clearTimeout(timeoutHandle));
                   });
                 });
    
                 // Wait for all spawned scenarios for this turn to complete
                 const scenarioOutputs = await Promise.all(scenarioPromises);
                 await log(sessionId, 'mother', 'debug', `All ${hypotheses.length} scenarios for this turn completed.`, { repoPath });
    
                 // Add combined scenario outputs as a single user message
                 messages.push({ role: 'user', content: scenarioOutputs.join('\n\n---\n\n') });
            } else {
                await log(sessionId, 'mother', 'debug', 'Hypothesis tag found, but no hypotheses extracted.', { repoPath });
            }
          } // End of hypothesis processing block
    
    
          // --- Observation Check ---
          // Check for new observations periodically or based on logic
          // Example: check every few seconds or after specific events
          // if (Date.now() - lastObservationCheck > 10000) { // Check every 10s
              const newObservations = await getAgentObservations(repoPath, sessionId, 'mother');
              if (newObservations.length > observations.length) {
                const latestObservations = newObservations.slice(observations.length);
                messages.push(...latestObservations.map(obs => ({
                  role: 'user' as const,
                  content: `Scientific observation: ${obs}`
                })));
                observations = newObservations; // Update the baseline observation list
                await log(sessionId, 'mother', 'debug', `Added ${latestObservations.length} new observations.`, { repoPath });
              }
            //   lastObservationCheck = Date.now();
          // }
    
    
          // --- Prepare for Next LLM Call ---
          // Check for cancellation signal again before the next LLM call
          if (signal.aborted) {
            await log(sessionId, 'mother', 'info', 'Cancellation signal received before next LLM call.', { repoPath });
            break; // Exit loop if cancelled
          }
    
          // Make next LLM call using the updated message history
          await log(sessionId, 'mother', 'debug', `Sending message history (${messages.length} items) to LLM`, { model: llmConfig.model, provider: llmConfig.provider, repoPath });
          replyText = await callLlm(messages, llmConfig); // Update replyText for the next loop iteration
    
          if (!replyText) {
            // Log the failure and let the loop condition handle termination
            await log(sessionId, 'mother', 'warn', 'Received empty/malformed response from LLM', { provider: llmConfig.provider, model: llmConfig.model, repoPath });
            // Push a message indicating the failure, maybe helps LLM recover?
            messages.push({ role: 'user', content: 'INTERNAL_NOTE: Previous LLM call failed to return valid content.' });
          } else {
            // Add the valid response to messages history for the *next* turn
            messages.push({ role: 'assistant', content: replyText });
            await log(sessionId, 'mother', 'debug', 'Received response from LLM', { response: replyText, provider: llmConfig.provider, model: llmConfig.model, repoPath });
          }
    
          // Optional delay between cycles
          await new Promise(resolve => setTimeout(resolve, 1000));
        } // End of while loop
    
        // --- Loop Finished ---
        // Determine final status based on why the loop ended
        let finalStatusMessage: string;
        if (signal.aborted) {
          finalStatusMessage = 'Session cancelled by user request.';
          await log(sessionId, 'mother', 'info', finalStatusMessage, { repoPath });
        } else if (replyText?.includes('<solution>')) {
          const match = replyText.match(/<solution>([\s\S]*?)<\/solution>/);
          if (match && match[1].trim()) {
            finalStatusMessage = 'Solution found or investigation concluded.';
            await log(sessionId, 'mother', 'info', finalStatusMessage, { repoPath });
          } else {
            // Empty solution tag, treat as error
            finalStatusMessage = 'Loop terminated unexpectedly (empty solution tag)';
            await log(sessionId, 'mother', 'warn', finalStatusMessage, { repoPath });
            replyText = finalStatusMessage;
          }
        } else {
          // Loop likely ended due to empty replyText from LLM failure
          finalStatusMessage = 'Loop terminated unexpectedly (e.g., LLM error).';
          await log(sessionId, 'mother', 'warn', finalStatusMessage, { repoPath });
          replyText = finalStatusMessage; // Use status message as final content
        }

        // Structured record at the end
        if (useMemoryBank) {
          await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - ${new Date().toISOString()}
    ${error ? `Initial Error: ${error}` : ''}
    Final Status: ${finalStatusMessage}
    ${replyText}
    Scenarios Spawned: ${scenarioCounter}
    Duration: ${Math.round((Date.now() - startTime) / 1000)}s`, 'progress').catch(err => log(sessionId, 'mother', 'error', 'Failed to update memory bank progress log', { error: err }));
        }

        return replyText; // Return the last reply or status
    
      } catch (err) {
         // Catch unexpected errors during setup or within the loop if not handled
         const caughtError = err instanceof Error ? err : new Error(String(err));
         // Check if the error was due to cancellation signal during an operation
          if (signal.aborted) {
            await log(sessionId, 'mother', 'info', `Operation aborted during execution: ${caughtError.message}`, { repoPath });
            // Optionally update progress log for aborted state
            if (useMemoryBank) {
              await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - ABORTED - ${new Date().toISOString()}\nError during abort: ${caughtError.message}`, 'progress').catch(logErr => console.error("Mem bank log fail on abort:", logErr));
            }
            return 'Session cancelled during operation.'; // Return specific cancellation message
          } else {
            // Log and record other errors
            await log(sessionId, 'mother', 'error', `Mother agent failed: ${caughtError.message}`, { repoPath, stack: caughtError.stack });
            if (useMemoryBank) {
              await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - FAILED - ${new Date().toISOString()}\nError: ${caughtError.message}\nStack: ${caughtError.stack}`, 'progress').catch(logErr => console.error("Mem bank log fail on error:", logErr));
            }
            throw caughtError; // Re-throw unexpected errors
          }
      } finally {
          // Ensure any remaining scenario PIDs are cleaned up if the mother agent exits unexpectedly
          if (scenarioPids.size > 0) {
            await log(sessionId, 'mother', 'warn', `Mother agent exiting unexpectedly with ${scenarioPids.size} scenario PIDs still in registry. Attempting cleanup.`, { repoPath, pids: Array.from(scenarioPids) });
            for (const pid of scenarioPids) {
                 try { process.kill(pid, 'SIGTERM'); } catch (e) { /* ignore errors if process already gone */ }
            }
             // Give a moment then force kill
             await new Promise(resolve => setTimeout(resolve, 1000));
             for (const pid of scenarioPids) {
                 try { process.kill(pid, 'SIGKILL'); } catch (e) { /* ignore */ }
             }
             scenarioPids.clear(); // Clear the set
          }
      }
    } // End of runMotherAgent

=== src/scenario-agent.ts ===

// src/scenario-agent.ts

import { log } from './util/logger.js';
import { connectRequiredTools } from './util/mcp.js';
import { writeReport } from './util/reports.js';
import { ChatCompletionMessageParam } from 'openai/resources/chat/completions'; // Keep OpenAI type for structure
import { writeObservation, getAgentObservations } from './util/observations.js';
import { callLlm, getScenarioAgentPrompt } from './util/agent-utils.js';

const MAX_RUNTIME = 15 * 60 * 1000; // 15 minutes

// Define LlmConfig interface (can be moved to a shared types file later if needed)
interface LlmConfig {
  provider?: string;
  model?: string;
  maxTokens?: number;
  apiKey?: string; // Generic key, primarily used for OpenRouter for backward compatibility
  openrouterApiKey?: string; // Alias for apiKey, prefer this for new code
  baseURL?: string; // For OpenAI-compatible APIs
  openaiApiKey?: string; // For OpenAI and compatible providers
  geminiApiKey?: string;
  anthropicApiKey?: string;
}

interface ScenarioArgs {
  id: string;
  session: string;
  error: string;
  context: string;
  hypothesis: string;
  language: string;
  repoPath: string;
  filePath?: string;
  branch: string;
}

function parseArgs(args: string[]): ScenarioArgs {
  const result: Record<string, string> = {};
  for (let i = 0; i < args.length; i++) {
    if (args[i].startsWith('--')) {
      const key = args[i].slice(2);
      const value = args[i + 1] && !args[i + 1].startsWith('--') ? args[i + 1] : '';
      result[key] = value;
      if (value) i++;
    }
  }

  const repoPath = result.repo;
  if (!repoPath) {
    throw new Error('Required argument missing: --repo');
  }

  return {
    id: result.id || '',
    session: result.session || '',
    error: result.error || '',
    context: result.context || '',
    hypothesis: result.hypothesis || '',
    language: result.language || 'typescript',
    repoPath,
    filePath: result.file || undefined,
    branch: result.branch || ''
  };
}

export async function runScenarioAgent(args: ScenarioArgs) {
  await log(args.session, `scenario-${args.id}`, 'info', 'Scenario agent started', { repoPath: args.repoPath, hypothesis: args.hypothesis });
  await log(
    args.session,
    `scenario-${args.id}`,
    'debug',
    `CWD: ${process.cwd()}, DEEBO_NPX_PATH=${process.env.DEEBO_NPX_PATH}, DEEBO_UVX_PATH=${process.env.DEEBO_UVX_PATH}`,
    { repoPath: args.repoPath }
  );
  try {
    // Set up tools
    await log(args.session, `scenario-${args.id}`, 'info', 'Connecting to tools...', { repoPath: args.repoPath });
  const { gitClient, filesystemClient } = await connectRequiredTools(
    `scenario-${args.id}`,
    args.session,
    args.repoPath
  );
  await log(args.session, `scenario-${args.id}`, 'info', 'Connected to tools successfully', { repoPath: args.repoPath });

    // Branch creation is handled by system infrastructure before this agent is spawned.

    // Start LLM conversation with initial context
    const startTime = Date.now();
    // Initial conversation context
    const messages: ChatCompletionMessageParam[] = [{
      role: 'assistant',
      content: getScenarioAgentPrompt({
        branch: args.branch,
        hypothesis: args.hypothesis,
        context: args.context,
        repoPath: args.repoPath
      })
    }, {
      role: 'user',
      content: `Error: ${args.error}
Context: ${args.context}
Language: ${args.language}
File: ${args.filePath}
Repo: ${args.repoPath}
Hypothesis: ${args.hypothesis}`
    }];

    // Check for observations (initial load)
    let observations = await getAgentObservations(args.repoPath, args.session, `scenario-${args.id}`);
    if (observations.length > 0) {
      messages.push(...observations.map((obs: string): ChatCompletionMessageParam => ({ // Added explicit type
        role: 'user' as const,
        content: `Scientific observation: ${obs}`
      })));
    }

    // Read LLM configuration from environment variables
    const scenarioProvider = process.env.SCENARIO_HOST; // Read provider name from SCENARIO_HOST
    const scenarioModel = process.env.SCENARIO_MODEL;
    const openrouterApiKey = process.env.OPENROUTER_API_KEY; // Still needed if provider is 'openrouter'
    const openaiApiKey = process.env.OPENAI_API_KEY;
    const openaiBaseUrl = process.env.OPENAI_BASE_URL;
    const geminiApiKey = process.env.GEMINI_API_KEY;
    const anthropicApiKey = process.env.ANTHROPIC_API_KEY;

    // Create the config object to pass to callLlm
    const llmConfig: LlmConfig = {
      provider: scenarioProvider, // Use the provider name from SCENARIO_HOST
      model: scenarioModel,
      apiKey: openrouterApiKey,
      openrouterApiKey: openrouterApiKey, // For OpenRouter
      openaiApiKey: openaiApiKey, // For OpenAI and compatible providers
      baseURL: openaiBaseUrl, // For OpenAI-compatible APIs
      geminiApiKey: geminiApiKey,
      anthropicApiKey: anthropicApiKey
    };

    await log(args.session, `scenario-${args.id}`, 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath: args.repoPath });
    let replyText = await callLlm(messages, llmConfig);
    if (!replyText) {
      await log(args.session, `scenario-${args.id}`, 'warn', 'Received empty/malformed response from LLM on initial call', { repoPath: args.repoPath });
      // Exit if the first call fails, as there's no response to process
      await writeReport(args.repoPath, args.session, args.id, 'Initial LLM call returned empty response.');
      console.log('Initial LLM call returned empty response.');
      process.exit(1);
    } else {
      messages.push({ role: 'assistant', content: replyText });
      await log(args.session, `scenario-${args.id}`, 'debug', 'Received from LLM', { response: { content: replyText }, repoPath: args.repoPath });
    }

    // --- Main Investigation Loop ---
    while (true) {
      if (Date.now() - startTime > MAX_RUNTIME) {
        const timeoutMsg = 'Investigation exceeded maximum runtime';
        await log(args.session, `scenario-${args.id}`, 'warn', timeoutMsg, { repoPath: args.repoPath });
        await writeReport(args.repoPath, args.session, args.id, timeoutMsg);
        console.log(timeoutMsg);
        process.exit(1);
      }

      // Get the latest assistant response
      const responseText = replyText; // replyText holds the latest LLM response

      // --- Check for Report and Tool Calls ---
      const toolCalls = responseText.match(/<use_mcp_tool>[\s\S]*?<\/use_mcp_tool>/g) || [];
      const reportMatch = responseText.match(/<report>\s*([\s\S]*?)<\/report>/i);

      let executeToolsThisTurn = false;
      let exitThisTurn = false;

      if (reportMatch && toolCalls.length > 0) {
          // LLM included both - prioritize executing tools, ignore report this turn
          messages.push({
              role: 'user',
              content: `Instructions conflict: You provided tool calls and a report in the same message. I will execute the tool calls now. Provide the report ONLY after analyzing the tool results in the next turn.`
          });
          executeToolsThisTurn = true; // Signal to execute tools below
          await log(args.session, `scenario-${args.id}`, 'warn', 'LLM provided tools and report simultaneously. Executing tools, ignoring report.', { repoPath: args.repoPath });

      } else if (reportMatch) {
          // Only report found - process it and exit
          const reportText = reportMatch[1].trim();
          await log(args.session, `scenario-${args.id}`, 'info', 'Report found. Writing report and exiting.', { repoPath: args.repoPath });
          await writeReport(args.repoPath, args.session, args.id, reportText);
          console.log(reportText); // Print report to stdout for mother agent
          exitThisTurn = true; // Signal to exit loop cleanly

      } else if (toolCalls.length > 0) {
           // Only tool calls found - execute them
           executeToolsThisTurn = true; // Signal to execute tools below
           await log(args.session, `scenario-${args.id}`, 'debug', `Found ${toolCalls.length} tool calls to execute.`, { repoPath: args.repoPath });
      }
      // If neither tools nor report found, the loop continues to the next LLM call

      // Exit now if a report-only response was processed
      if (exitThisTurn) {
           process.exit(0);
      }

      // --- Execute Tools if Flagged ---
      if (executeToolsThisTurn) {
        const parsedCalls = toolCalls.map((tc: string) => {
          try {
            const serverNameMatch = tc.match(/<server_name>(.*?)<\/server_name>/);
            if (!serverNameMatch || !serverNameMatch[1]) throw new Error('Missing server_name');
            const serverName = serverNameMatch[1];
            const server = serverName === 'git-mcp' ? gitClient! : filesystemClient!; // Select client based on name
            if (!server) throw new Error(`Invalid server_name: ${serverName}`);

            const toolMatch = tc.match(/<tool_name>(.*?)<\/tool_name>/);
            if (!toolMatch || !toolMatch[1]) throw new Error('Missing tool_name');
            const tool = toolMatch[1]!;

            const argsMatch = tc.match(/<arguments>(.*?)<\/arguments>/s);
            if (!argsMatch || !argsMatch[1]) throw new Error('Missing arguments');
            const args = JSON.parse(argsMatch[1]!);

            return { server, tool, args };
          } catch (err) {
            const errorMsg = err instanceof Error ? err.message : String(err);
            log(args.session, `scenario-${args.id}`, 'error', `Failed to parse tool call: ${errorMsg}`, { toolCall: tc, repoPath: args.repoPath });
            return { error: errorMsg }; // Return error object for specific call
          }
        });

        // Process each parsed call - add results or errors back to messages
        let toolCallFailed = false;
        for (const parsed of parsedCalls) {
          if ('error' in parsed) {
            messages.push({
              role: 'user',
              content: `Tool call parsing failed: ${parsed.error}`
            });
            toolCallFailed = true; // Mark failure, but continue processing other calls if needed, or let LLM handle it next turn
            continue; // Skip execution for this malformed call
          }

          // Prevent disallowed tools
          if (parsed.tool === 'git_create_branch') {
              messages.push({
                role: 'user',
                content: 'Error: Tool call `git_create_branch` is not allowed. The branch was already created by the mother agent.'
              });
              await log(args.session, `scenario-${args.id}`, 'warn', `Attempted disallowed tool call: ${parsed.tool}`, { repoPath: args.repoPath });
              continue; // Skip this specific call
          }

          try {
              await log(args.session, `scenario-${args.id}`, 'debug', `Executing tool: ${parsed.tool}`, { args: parsed.args, repoPath: args.repoPath });
              const result = await parsed.server.callTool({ name: parsed.tool, arguments: parsed.args });
              messages.push({
                role: 'user',
                content: JSON.stringify(result) // Tool results are added as user messages
              });
              await log(args.session, `scenario-${args.id}`, 'debug', `Tool result for ${parsed.tool}`, { result: result, repoPath: args.repoPath });
          } catch (toolErr) {
              const errorMsg = toolErr instanceof Error ? toolErr.message : String(toolErr);
              messages.push({
                role: 'user',
                content: `Tool call failed for '${parsed.tool}': ${errorMsg}`
              });
              await log(args.session, `scenario-${args.id}`, 'error', `Tool call execution failed: ${parsed.tool}`, { error: errorMsg, repoPath: args.repoPath });
              toolCallFailed = true; // Mark failure
          }
        }
        // Decide if we should immediately ask LLM again after tool failure, or let the loop naturally continue.
        // Current logic lets loop continue, LLM will see the error messages.
      }

      // --- Check for New Observations ---
      const newObservations = await getAgentObservations(args.repoPath, args.session, `scenario-${args.id}`);
      if (newObservations.length > observations.length) {
        const latestObservations = newObservations.slice(observations.length);
        messages.push(...latestObservations.map((obs: string): ChatCompletionMessageParam => ({
          role: 'user',
          content: `Scientific observation: ${obs}`
        })));
        observations = newObservations; // Update the baseline observation list
        await log(args.session, `scenario-${args.id}`, 'debug', `Added ${latestObservations.length} new observations to context.`, { repoPath: args.repoPath });
      }

      // --- Make Next LLM Call ---
      await log(args.session, `scenario-${args.id}`, 'debug', `Sending message history (${messages.length} items) to LLM`, { model: llmConfig.model, provider: llmConfig.provider, repoPath: args.repoPath });
      replyText = await callLlm(messages, llmConfig); // Update replyText for the next loop iteration
      if (!replyText) {
        // LLM failed mid-conversation
        const errorMsg = 'LLM returned empty response mid-investigation.';
        await log(args.session, `scenario-${args.id}`, 'error', errorMsg, { provider: llmConfig.provider, model: llmConfig.model, repoPath: args.repoPath });
        await writeReport(args.repoPath, args.session, args.id, errorMsg);
        console.log(errorMsg);
        process.exit(1);
      } else {
        // Add the valid response to messages history for the *next* turn
        messages.push({ role: 'assistant', content: replyText });
        await log(args.session, `scenario-${args.id}`, 'debug', 'Received response from LLM', { responseLength: replyText.length, provider: llmConfig.provider, model: llmConfig.model, repoPath: args.repoPath });
      }

      // Small delay before next iteration (optional)
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  } catch (error) {
    // Catch unexpected errors during setup or within the loop if not handled
    const errorText = error instanceof Error ? `${error.message}${error.stack ? `\nStack: ${error.stack}` : ''}` : String(error);
    await log(args.session, `scenario-${args.id}`, 'error', `Unhandled scenario error: ${errorText}`, { repoPath: args.repoPath });
    await writeReport(args.repoPath, args.session, args.id, `SCENARIO FAILED UNEXPECTEDLY: ${errorText}`);
    console.error(`SCENARIO FAILED UNEXPECTEDLY: ${errorText}`); // Log error to stderr as well
    process.exit(1);
  }
}

// --- Script Entry Point ---
try {
    const args = parseArgs(process.argv.slice(2)); // Pass relevant args, skipping node path and script path
    runScenarioAgent(args); // No await here, let the async function run
} catch (err) {
    // Handle argument parsing errors
    const errorText = err instanceof Error ? err.message : String(err);
    console.error(`Scenario agent failed to start due to arg parsing error: ${errorText}`);
    // Attempt to log if possible, though session info might be missing
    // log(args.session || 'unknown', `scenario-${args.id || 'unknown'}`, 'error', `Arg parsing failed: ${errorText}`, {}).catch();
    process.exit(1);
}

// Optional: Add unhandled rejection/exception handlers for more robustness
process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
  // Log this? Might be hard without session context.
  process.exit(1); // Exit on unhandled promise rejection
});

process.on('uncaughtException', (error) => {
  console.error('Uncaught Exception:', error);
  // Log this?
  process.exit(1); // Exit on uncaught exception
});
=== package.json ===

{
  "name": "deebo-prototype",
  "version": "1.0.0",
  "main": "build/index.js",
  "bin": {
    "deebo": "build/index.js"
  },
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node --experimental-specifier-resolution=node --experimental-modules --max-old-space-size=4096 build/index.js",
    "dev": "tsc --watch & node --experimental-specifier-resolution=node --experimental-modules --max-old-space-size=4096 --watch build/index.js",
    "setup": "bash setup.sh",
    "setup:win": "powershell -ExecutionPolicy Bypass -File .\\setup.ps1",
    "check-env": "node check-env.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "Agentic Debugging System that integrates with Git and Filesystem MCP servers",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.39.0",
    "@google/generative-ai": "^0.24.0",
    "@modelcontextprotocol/sdk": "^1.7.0",
    "@modelcontextprotocol/server-filesystem": "^2025.1.14",
    "@wonderwhy-er/desktop-commander": "^0.1.31",
    "cors": "^2.8.5",
    "dockerode": "^4.0.0",
    "dotenv": "^16.4.7",
    "express": "^5.0.1",
    "openai": "^4.91.1",
    "p-limit": "^6.2.0",
    "simple-git": "^3.27.0",
    "urlpattern-polyfill": "^10.0.0",
    "uuid": "^11.1.0",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/dockerode": "^3.3.23",
    "@types/express": "^5.0.1",
    "@types/node": "^22.13.14",
    "@types/uuid": "^9.0.8",
    "typescript": "^5.8.2"
  },
  "resolutions": {
    "@modelcontextprotocol/sdk": "1.7.0"
  }
}

=== tsconfig.json ===

{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./build",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "allowJs": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "lib": ["ES2022"],
    "types": ["node"]
  },
  "include": ["src/**/*"]
}

=== README.md ===


# Deebo: Your AI Agent's Debugging Partner
[![npm version](https://img.shields.io/npm/v/deebo-setup.svg)](https://www.npmjs.com/package/deebo-setup)
[![GitHub stars](https://img.shields.io/github/stars/snagasuri/deebo-prototype?style=social)](https://github.com/snagasuri/deebo-prototype)
[![Active installs](https://img.shields.io/endpoint?url=https://deebo-active-counter.ramnag2003.workers.dev/active)](https://github.com/snagasuri/deebo-prototype)

Deebo is an autonomous debugging system that AI coding agents (Claude, Cline, Cursor, etc.) can delegate tricky bugs to using the Model Context Protocol (MCP). It runs structured investigations in parallel Git branches to test hypotheses, validate fixes, and helps you move faster. If your main coding agent is like a single-threaded process, Deebo introduces multi-threadedness to your development workflow.

**feedback, questions/support? dm me on x @sriramenn or open an issue here**

**If you think your team can benefit from Deebo, we’d love to hear from you.**
We’re partnering with teams who use AI agents to write production code and want to maximize their productivity.
Reach out for a live walkthrough, custom setup support, or to explore early access to enterprise features.

<video src="https://github.com/user-attachments/assets/756d35b4-4f77-48de-bd1a-86f76360279e" controls width="100%"></video>
**40-second sped-up video of Deebo in action on a real codebase**


Deebo scales to production codebases, too. Here's [an example of Deebo solving the test53 linearizer failure $100 tinygrad bug bounty](https://github.com/snagasuri/deebo-prototype/tree/master/memory-bank/9bd38e9840d3/sessions/session-1744006973678) by spawning 17 scenario agents and coming up with 2 valid fixes. Check out [progress.md](https://github.com/snagasuri/deebo-prototype/blob/master/memory-bank/9bd38e9840d3/progress.md) for just the solution.

## 🚀 Quick Install (for Cline/Claude Desktop users) 
```bash
npx deebo-setup
```
That's it! Follow the prompts to configure your API key and you're ready to go.

**show us you're alive!!**
```bash
npx deebo-setup ping
```
## Cursor users: https://cursor.directory/mcp/deebo

<details>
<summary>🛠️ Manual Installation (for other setups)</summary>

If you're not using Cline or Claude Desktop, follow these steps:

1. Clone the repo:
   ```bash
   git clone https://github.com/snagasuri/deebo-prototype.git
   cd deebo-prototype
   ```

2. Install dependencies:
   ```bash
   npm install
   npm run build
   ```

3. Install required MCP tools:
   ```bash
   # Install uv/uvx
   curl -LsSf https://astral.sh/uv/install.sh | sh

   # Install git-mcp
   uvx mcp-server-git --help

   # Install desktop-commander
   npx @wonderwhy-er/desktop-commander@latest setup
   ```

4. Configure your MCP client to use Deebo 

### MCP Configuration
```json
{
  "mcpServers": {
    "deebo": {
      "autoApprove": [],
      "disabled": false,
      "timeout": 30,
      "command": "node",
      "args": [
        "--experimental-specifier-resolution=node",
        "--experimental-modules",
        "--max-old-space-size=4096",
        "/absolute/path/to/deebo/build/index.js"
      ],
      "env": {
        "NODE_ENV": "development",
        "USE_MEMORY_BANK": "true",
        "MOTHER_HOST": "openrouter",
        "MOTHER_MODEL": "anthropic/claude-3.5-sonnet",
        "SCENARIO_HOST": "openrouter",
        "SCENARIO_MODEL": "anthropic/claude-3.5-sonnet",
        "OPENROUTER_API_KEY": "sk-or-v1-..."
      },
      "transportType": "stdio"
    }
  }
}
```
</details>

<details>
<summary>🔧 Development Guide</summary>

### Prerequisites
- **Git**: For version control
- **Node.js**: v18+ (includes npm)
- **Python**: 3.10+ (for git-mcp)

### Configuration Files
- **Cline:** `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`
- **Claude Desktop:** `~/Library/Application Support/Claude/claude_desktop_config.json`

### LLM Support
Deebo supports OpenRouter, Anthropic, OpenAI SDK, and Gemini models. Configure via environment variables:
- `MOTHER_HOST`: LLM provider for mother agent
- `SCENARIO_HOST`: LLM provider for scenario agents
- `[PROVIDER]_API_KEY`: API key for chosen provider
- Any other OpenAI-compatible API endpoint
  - `OPENAI_API_KEY` to your API key (e.g., `'ollama'` for Ollama)
  - `OPENAI_BASE_URL` to your API endpoint (e.g., `'http://localhost:11434/v1'` for Ollama)

See `src/util/agent-utils.ts` for supported models and configuration details.
</details>

## 📜 License

This project is licensed under the Apache License, Version 2.0 - see the [LICENSE](LICENSE) file for details.

Copyright 2025 Sriram Nagasuri
