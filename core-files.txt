
=== src/util/sanitize.ts ===

// src/util/sanitize.ts
import { createHash } from 'crypto';

export function getProjectId(repoPath: string): string {
  const hash = createHash('sha256').update(repoPath).digest('hex');
  return hash.slice(0, 12); // use first 12 characters
}
=== src/util/reports.ts ===

import { mkdir, writeFile } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// src/util/reports.ts
//we changed it to text to make check tool work better then changed it back to json
// after removing validation.ts which was blocking access to memory bank files 
// but really inelegantly so i took it out but i might have not reverted all the 
// changes so there's probably that if you're still getting bugs
export async function writeReport(repoPath: string, sessionId: string, scenarioId: string, report: string) {
    const projectId = getProjectId(repoPath);
    const reportDir = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'reports');
    await mkdir(reportDir, { recursive: true });
    const reportPath = join(reportDir, `${scenarioId}.json`);
    await writeFile(reportPath, JSON.stringify(report, null, 2));
}

=== src/util/branch-manager.ts ===

// src/util/branch-manager.ts
import { simpleGit } from 'simple-git';

// note: second parameter is `scenarioId`
export async function createScenarioBranch(repoPath: string, scenarioId: string): Promise<string> {
  const git = simpleGit(repoPath);
  const branchName = `debug-${scenarioId}`;  // e.g. debug-session-1745287764331-0
  await git.checkoutLocalBranch(branchName);
  return branchName;
}
=== src/util/agent-utils.ts ===

import { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import { GoogleGenerativeAI, Content, Part } from "@google/generative-ai";
import Anthropic from "@anthropic-ai/sdk"; // Import the default export
import { MessageParam } from "@anthropic-ai/sdk/resources/messages.mjs"; // Import the specific type
import OpenAI from "openai";
import { ChatModel } from 'openai/resources';

// Define an interface for the configuration passed from agents
interface LlmConfig {
  provider?: string;
  model?: string;
  maxTokens?: number;
  apiKey?: string; // Generic key, primarily used for OpenRouter for backward compatibility
  openrouterApiKey?: string; // Alias for apiKey, prefer this for new code
  baseURL?: string; // For OpenAI-compatible APIs
  openaiApiKey?: string; // For OpenAI and compatible providers
  geminiApiKey?: string;
  anthropicApiKey?: string;
}

/**
 * Generates the mother agent's system prompt with the given parameters
 */
export function getMotherAgentPrompt(useMemoryBank: boolean, memoryBankPath: string): string {
  return `You are the mother agent in an OODA loop debugging investigation. Your core mission:

1. INVESTIGATE and HYPOTHESIZE aggressively
2. Don't wait for perfect information
3. Generate hypotheses even if you're uncertain

KEY DIRECTIVES:
- Always generate at least one hypothesis within your first 2-3 responses
- Use <hypothesis>Your hypothesis here</hypothesis> liberally
- Better to spawn 5 wrong scenario agents than miss the right one
- If you see an error message, immediately form hypotheses about its causes
- Don't wait for full context - start with what you have
- AVOID REDUNDANT HYPOTHESES - read scenario reports to learn what's been tried
- Pass what failed to scenarios via context argument so they don't waste time
- Take notes! You're a scientist mother (think Dr. Akagi), not a robot. Be creative and curious.

SOLUTION CONFIDENCE:
Only use <solution> tags when you are at least 96% confident in the solution.
If your confidence is lower:
- Create your own branch to test it
- Keep investigating (you have the same tools as scenarios)
- Generate new hypotheses if needed
Solution tags = "I am at least 96% confident this works"
When you've found a solution or determined none exists, wrap it in solution tags:
<solution>Your final conclusion and solution here</solution>
${useMemoryBank ? `
MEMORY BANK INVESTIGATION AIDS:
The memory bank at ${memoryBankPath} contains two key files to help your investigation:

1. activeContext.md - Your live investigation notebook:
- READ THIS FIRST when starting an investigation using ${memoryBankPath}/activeContext.md
- Contains your previous debugging notes and observations
- Shows which approaches were promising vs dead ends
- Records important error patterns you've noticed
- Use this to avoid repeating failed approaches
- Read this to understand which parts of the code were already examined
- To edit, use read_file to get the latest state, then write a targeted diff using edit_file instead of write_file to avoid overwriting

2. progress.md - The full debugging history (access at ${memoryBankPath}/progress.md):
- Contains complete records of all debug sessions
- Shows which hypotheses were tried and their outcomes
- Lists all scenarios that were run and their results
- Use this to see if similar bugs were fixed before

Use these files to:
- Build on previous investigation progress
- Spot patterns in failing scenarios
- Generate better hypotheses based on what's worked/failed
- Provide relevant context to scenario agents
- Track the evolution of your debugging approach
- Take notes! You're a scientist mother (think Dr. Akagi), not a robot. Be creative and curious.

IMPORTANT: Always use ${memoryBankPath} as the absolute path for memory bank files. Never use relative paths.
` : ''}

TOOL USAGE:
Always use this exact format for tools:
<use_mcp_tool>
  <server_name>git-mcp</server_name>
  <tool_name>git_status</tool_name>
  <arguments>
    {
      "repo_path": "/path/to/repo"
    }
  </arguments>
</use_mcp_tool>

Available Tools:
git-mcp (use for ALL git operations):
- git_status: Show working tree status
  Example: { "repo_path": "/path/to/repo" }
- git_diff_unstaged: Show changes in working directory not yet staged
  Example: { "repo_path": "/path/to/repo" }
- git_diff_staged: Show changes that are staged for commit
  Example: { "repo_path": "/path/to/repo" }
- git_diff: Compare current state with a branch or commit
  Example: { "repo_path": "/path/to/repo", "target": "main" }
- git_add: Stage file changes
  Example: { "repo_path": "/path/to/repo", "files": ["file1.ts", "file2.ts"] }
- git_commit: Commit staged changes
  Example: { "repo_path": "/path/to/repo", "message": "commit message" }
- git_reset: Unstage all changes
  Example: { "repo_path": "/path/to/repo" }
- git_log: Show recent commit history
  Example: { "repo_path": "/path/to/repo" }
- git_checkout: Switch to a different branch
  Example: { "repo_path": "/path/to/repo", "branch_name": "debug-123" }
- git_show: Show contents of a specific commit
  Example: { "repo_path": "/path/to/repo", "revision": "HEAD" }

desktop-commander (use ONLY for non-git operations):

Terminal Tools:
- execute_command: Run terminal commands with timeout
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>execute_command</tool_name>
    <arguments>
      {
        "command": "npm run build",
        "timeout_ms": 5000
      }
    </arguments>
  </use_mcp_tool>

- read_output: Get output from running commands
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_output</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- force_terminate: Stop running command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>force_terminate</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- list_sessions: View active command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_sessions</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- list_processes: List system processes
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_processes</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- kill_process: Terminate processes by PID
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>kill_process</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- block_command: Block a command from execution
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>block_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

- unblock_command: Unblock a command
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>unblock_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

Filesystem Tools:
- read_file: Read file contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_file</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}/activeContext.md"
      }
    </arguments>
  </use_mcp_tool>

- read_multiple_files: Read multiple files at once
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_multiple_files</tool_name>
    <arguments>
      {
        "paths": ["file1.ts", "file2.ts"]
      }
    </arguments>
  </use_mcp_tool>

- write_file: Write content to files
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>write_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "content": "console.log('hello');"
      }
    </arguments>
  </use_mcp_tool>

- edit_file: Apply surgical text replacements
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>edit_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "diff": "<<<<<<< SEARCH\nold code\n=======\nnew code\n>>>>>>> REPLACE"
      }
    </arguments>
  </use_mcp_tool>

- list_directory: List directory contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_directory</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}"
      }
    </arguments>
  </use_mcp_tool>

- search_files: Search files with pattern
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_files</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}",
        "pattern": "error",
        "file_pattern": "*.ts"
      }
    </arguments>
  </use_mcp_tool>

- create_directory: Create a new directory
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>create_directory</tool_name>
    <arguments>
      {
        "path": "new-dir"
      }
    </arguments>
  </use_mcp_tool>

- move_file: Move or rename a file
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>move_file</tool_name>
    <arguments>
      {
        "source": "old.ts",
        "destination": "new.ts"
      }
    </arguments>
  </use_mcp_tool>

- get_file_info: Get file metadata
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>get_file_info</tool_name>
    <arguments>
      {
        "path": "file.ts"
      }
    </arguments>
  </use_mcp_tool>

- search_code: Recursive code search
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_code</tool_name>
    <arguments>
      {
        "path": "${memoryBankPath}",
        "pattern": "function",
        "filePattern": "*.ts",
        "contextLines": 2,
        "ignoreCase": true
      }
    </arguments>
  </use_mcp_tool>

IMPORTANT MEMORY BANK WARNINGS:
- DO NOT use write_file on memory bank files - use filesystem-mcp edit_file instead
- Only edit memory bank through edit_file to avoid overwrites
- Always use ${memoryBankPath} as absolute path for memory bank files`;
}



/**
 * Generates the scenario agent's system prompt with the given parameters
 */
export function getScenarioAgentPrompt(args: {
  branch: string;
  hypothesis: string;
  context: string;
  repoPath: string;
}): string {
  return `You are a scenario agent investigating a bug based on a specific hypothesis.
A dedicated Git branch '${args.branch}' has been created for your investigation.

Your hypothesis: "${args.hypothesis}"
Your job is to either validate the hypothesis, falsify it, or propose alternative directions if stuck. You do not need to fix the entire bug — your focus is the truth of the SPECIFIC hypothesis you are assigned to.
That being said, don't be too hasty to report a conclusion. If you see something potentially useful/interesting, investigate it further. Debugging is a complicated, nonlinear process, and subtle clues could be useful.
IMPORTANT:
- READ THE CONTEXT CAREFULLY: "${args.context}"
- This contains what approaches have failed and why
- Don't waste time repeating failed attempts
- These are instructions, not suggestions. Do not retry any approach listed here as 'already attempted'.
- Mother agent is counting on you to explore NEW approaches
- When you're reasonably confident, wrap up with <report> tags

TOOL USAGE:
Always use this exact format for tools:
<use_mcp_tool>
  <server_name>git-mcp</server_name>
  <tool_name>git_status</tool_name>
  <arguments>
    {
      "repo_path": "${args.repoPath}"
    }
  </arguments>
</use_mcp_tool>

Available Tools:
git-mcp (use for ALL git operations):
- git_status: Show working tree status
  Example: { "repo_path": "${args.repoPath}" }
- git_diff_unstaged: Show changes in working directory not yet staged
  Example: { "repo_path": "${args.repoPath}" }
- git_diff_staged: Show changes that are staged for commit
  Example: { "repo_path": "${args.repoPath}" }
- git_diff: Compare current state with a branch or commit
  Example: { "repo_path": "${args.repoPath}", "target": "main" }
- git_add: Stage file changes
  Example: { "repo_path": "${args.repoPath}", "files": ["file1.ts", "file2.ts"] }
- git_commit: Commit staged changes
  Example: { "repo_path": "${args.repoPath}", "message": "commit message" }
- git_reset: Unstage all changes
  Example: { "repo_path": "${args.repoPath}" }
- git_log: Show recent commit history
  Example: { "repo_path": "${args.repoPath}" }
- git_show: Show contents of a specific commit
  Example: { "repo_path": "${args.repoPath}", "revision": "HEAD" }

desktop-commander (use ONLY for non-git operations):

Terminal Tools:
- execute_command: Run terminal commands with timeout
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>execute_command</tool_name>
    <arguments>
      {
        "command": "npm run build",
        "timeout_ms": 5000
      }
    </arguments>
  </use_mcp_tool>

- read_output: Get output from running commands
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_output</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- force_terminate: Stop running command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>force_terminate</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- list_sessions: View active command sessions
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_sessions</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- list_processes: List system processes
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_processes</tool_name>
    <arguments>
      {}
    </arguments>
  </use_mcp_tool>

- kill_process: Terminate processes by PID
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>kill_process</tool_name>
    <arguments>
      {
        "pid": 12345
      }
    </arguments>
  </use_mcp_tool>

- block_command: Block a command from execution
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>block_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

- unblock_command: Unblock a command
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>unblock_command</tool_name>
    <arguments>
      {
        "command": "rm -rf /"
      }
    </arguments>
  </use_mcp_tool>

Filesystem Tools:
- read_file: Read file contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_file</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}/file.ts"
      }
    </arguments>
  </use_mcp_tool>

- read_multiple_files: Read multiple files at once
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>read_multiple_files</tool_name>
    <arguments>
      {
        "paths": ["file1.ts", "file2.ts"]
      }
    </arguments>
  </use_mcp_tool>

- write_file: Write content to files
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>write_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "content": "console.log('hello');"
      }
    </arguments>
  </use_mcp_tool>

- edit_file: Apply surgical text replacements
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>edit_file</tool_name>
    <arguments>
      {
        "path": "file.ts",
        "diff": "<<<<<<< SEARCH\nold code\n=======\nnew code\n>>>>>>> REPLACE"
      }
    </arguments>
  </use_mcp_tool>

- list_directory: List directory contents
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>list_directory</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}"
      }
    </arguments>
  </use_mcp_tool>

- search_files: Search files with pattern
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_files</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}",
        "pattern": "error",
        "file_pattern": "*.ts"
      }
    </arguments>
  </use_mcp_tool>

- create_directory: Create a new directory
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>create_directory</tool_name>
    <arguments>
      {
        "path": "new-dir"
      }
    </arguments>
  </use_mcp_tool>

- move_file: Move or rename a file
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>move_file</tool_name>
    <arguments>
      {
        "source": "old.ts",
        "destination": "new.ts"
      }
    </arguments>
  </use_mcp_tool>

- get_file_info: Get file metadata
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>get_file_info</tool_name>
    <arguments>
      {
        "path": "file.ts"
      }
    </arguments>
  </use_mcp_tool>

- search_code: Recursive code search
  Example:
  <use_mcp_tool>
    <server_name>desktop-commander</server_name>
    <tool_name>search_code</tool_name>
    <arguments>
      {
        "path": "${args.repoPath}",
        "pattern": "function",
        "filePattern": "*.ts",
        "contextLines": 2,
        "ignoreCase": true
      }
    </arguments>
  </use_mcp_tool>

REPORT FORMAT:
When you've completed your investigation, use:
<report>
HYPOTHESIS: [Original hypothesis]
CONFIRMED: [Yes/No/Partially]
INVESTIGATION:
[Briefly explain what context you took into account and how this differed]
[Summary of what you tried]
[Key findings]
[Why this confirms/refutes hypothesis]

CHANGES MADE:
[List any file changes]
[Why each change was needed]

CONFIDENCE: [High/Medium/Low]
[Explanation of confidence level]
</report>`;
}


export async function callLlm(
  messages: ChatCompletionMessageParam[],
  config: LlmConfig
): Promise<string> {
  const {
    provider,
    model,
    maxTokens = 4096,
    apiKey,
    openrouterApiKey,
    baseURL,
    openaiApiKey,
    geminiApiKey,
    anthropicApiKey
  } = config;

  const lowerCaseProvider = provider?.toLowerCase();

  if (lowerCaseProvider === 'openai') {
    if (!openaiApiKey) throw new Error("API key is required for 'openai' provider.");
    if (!baseURL) throw new Error("Base URL is required for 'openai' provider.");
    const openai = new OpenAI({
      apiKey: openaiApiKey,
      baseURL: baseURL,
    });
    const completion = await openai.chat.completions.create({
      model: (model || 'gpt-4o') as ChatModel,
      max_tokens: maxTokens,
      messages
    });
    return completion.choices?.[0]?.message?.content || '';
  }

  if (lowerCaseProvider === 'openrouter') {
    if (!openrouterApiKey && !apiKey) throw new Error("OpenRouter API key is required for 'openrouter' provider.");
    const openai = new OpenAI({
      apiKey: openrouterApiKey || apiKey, // Use new name if available, fall back to old name
      baseURL: 'https://openrouter.ai/api/v1',
    });
    const completion = await openai.chat.completions.create({
      model: (model || 'openai/gpt-4o') as ChatModel, // Use provided model or default
      max_tokens: maxTokens,
      messages
    });
    return completion.choices?.[0]?.message?.content || '';
  }

  if (lowerCaseProvider === 'gemini') {
    if (!geminiApiKey) throw new Error("Gemini API key is required for 'gemini' provider.");
    const gemini = new GoogleGenerativeAI(geminiApiKey);
    const model_name = model || 'gemini-1.5-pro'; // Use provided model or default
    const genModel = gemini.getGenerativeModel({ model: model_name });

    // Correctly map messages to Gemini's Content[] format
    const geminiHistory: Content[] = messages.map(m => ({
      role: m.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: m.content as string }] as Part[] // Ensure parts is an array of Part
    }));

    const result = await genModel.generateContent({
      contents: geminiHistory,
      generationConfig: {
        maxOutputTokens: maxTokens
      }
    });
    const response = await result.response;
    return response.text() || '';
  }

  if (lowerCaseProvider === 'anthropic') {
    if (!anthropicApiKey) throw new Error("Anthropic API key is required for 'anthropic' provider.");
    const anthropic = new Anthropic({ apiKey: anthropicApiKey });
    // Correctly map messages to Anthropic's MessageParam[] format with explicit roles
    const anthropicMessages: MessageParam[] = messages.map(m => ({
      role: (m.role === 'assistant' ? 'assistant' : 'user') as 'user' | 'assistant',
      content: m.content as string
    }));

    const raw = await anthropic.messages.create({
      model: (model || 'claude-3-sonnet-20240229') as any, // Use provided model or default
      max_tokens: maxTokens,
      messages: anthropicMessages,
    });
    // Check if the first content block is a TextBlock before accessing text
    const firstContent = raw.content[0];
    return firstContent && firstContent.type === 'text' ? firstContent.text : '';
  }

  throw new Error(`Unsupported provider '${lowerCaseProvider}'. Set LLM_PROVIDER env var to 'openai', 'openrouter', 'gemini', or 'anthropic'`);
}

=== src/util/mcp.ts ===

// src/util/mcp.ts
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { readFile, writeFile } from 'fs/promises';
import { join } from 'path';
import * as path from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// Map to track active connections
const activeConnections: Map<string, Promise<Client>> = new Map();

export async function connectMcpTool(name: string, toolName: string, sessionId: string, repoPath: string) {
  const rawConfig = JSON.parse(await readFile(join(DEEBO_ROOT, 'config', 'tools.json'), 'utf-8'));
  const def = rawConfig.tools[toolName];
  const memoryPath = join(DEEBO_ROOT, 'memory-bank', getProjectId(repoPath));
  const memoryRoot = join(DEEBO_ROOT, 'memory-bank');

  /* --- WINDOWS-ONLY PATCH ----------------------------------------- */
  if (process.platform === "win32" && toolName === "desktopCommander") {
    // Use the real *.cmd so the process owns stdin/stdout
    const cmdPath = path.join(process.env.DEEBO_NPM_BIN!, "desktop-commander.cmd");
    def.command = cmdPath;
    def.args = ["serve"];            // same behaviour as 'npx … serve'
  }
  /* ---------------------------------------------------------------- */

  // Substitute npx/uvx paths directly in the command
  let command = def.command
    .replace(/{npxPath}/g, process.env.DEEBO_NPX_PATH!)
    .replace(/{uvxPath}/g, process.env.DEEBO_UVX_PATH!);
  
  // Replace placeholders in all args
  let args = def.args.map((arg: string) =>
    arg
      .replace(/{repoPath}/g, repoPath)
      .replace(/{memoryPath}/g, memoryPath)
      .replace(/{memoryRoot}/g, memoryRoot)
  );

  // No shell: spawn the .cmd/binary directly on all platforms
  const options = {};

  const transport = new StdioClientTransport({ command, args, ...options });
  const client = new Client({ name, version: '1.0.0' }, { capabilities: { tools: true } });
  await client.connect(transport);
  return client;
}

export async function connectRequiredTools(agentName: string, sessionId: string, repoPath: string): Promise<{
  gitClient: Client;
  filesystemClient: Client;
}> {
  const [gitClient, filesystemClient] = await Promise.all([
    connectMcpTool(`${agentName}-git`, 'git-mcp', sessionId, repoPath),
    // Switch from "filesystem-mcp" to "desktop-commander"
    connectMcpTool(`${agentName}-desktop-commander`, 'desktopCommander', sessionId, repoPath)
  ]);

  return { gitClient, filesystemClient };
}

=== src/util/logger.ts ===

import { writeFile, mkdir } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

// Write logs to memory bank structure
export async function log(sessionId: string, name: string, level: string, message: string, data?: any) {
  const entry = JSON.stringify({
    timestamp: new Date().toISOString(),
    agent: name,
    level,
    message,
    data
  }) + '\n';

  // Data will be written to memory-bank/projectId/sessions/sessionId/logs/agentName.log
  const projectId = getProjectId(data?.repoPath);
  if (projectId) {
    const logPath = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'logs', `${name}.log`);
    await writeFile(logPath, entry, { flag: 'a' });
  }
}

// Simple console logging
export function consoleLog(level: string, message: string, data?: any) {
  console.log(`[${level}] ${message}`, data || '');
}

=== src/util/membank.ts ===

// src/util/membank.js
import { join } from 'path';
import { writeFile } from 'fs/promises';
import { DEEBO_ROOT } from '../index.js';

export async function updateMemoryBank(projectId: string, content: string, file: 'activeContext' | 'progress'): Promise<void> {
  const path = join(DEEBO_ROOT, 'memory-bank', projectId, `${file}.md`);
  await writeFile(path, '\n' + content, { flag: 'a' });
}
=== src/util/observations.ts ===

import { writeFile, mkdir, readFile } from 'fs/promises';
import { join } from 'path';
import { DEEBO_ROOT } from '../index.js';
import { getProjectId } from './sanitize.js';

export async function getAgentObservations(repoPath: string, sessionId: string, agentId: string): Promise<string[]> {
  const projectId = getProjectId(repoPath);
  const obsPath = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'observations', `${agentId}.log`);
  
  try {
    const content = await readFile(obsPath, 'utf8');
    return content
      .split('\n')
      .filter(Boolean)
      .map((line: string) => JSON.parse(line).observation);
  } catch {
    return []; // No observations yet
  }
}

export async function writeObservation(repoPath: string, sessionId: string, agentId: string, observation: string) {
  const projectId = getProjectId(repoPath);
  const obsDir = join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'observations');
  await mkdir(obsDir, { recursive: true });
  
  const entry = JSON.stringify({
    timestamp: new Date().toISOString(),
    observation
  }) + '\n';
  
  await writeFile(join(obsDir, `${agentId}.log`), entry, { flag: 'a' });
}

=== src/mother-agent.ts ===

// src/mother-agent.ts
/**
 * 📌 Why this is the best version:
    •	✅ Keeps full message history without resetting
    •	✅ Supports multiple tool calls per Claude response
    •	✅ Spawns scenarios from multiple hypotheses
    •	✅ Never throws on malformed XML, logs gently instead
    •	✅ Doesn't force memory bank writes — Mother can directly choose via filesystem-mcp
    •	✅ Maintains Deebo's spirit: autonomy, freedom to fail, and graceful continuation
 */

    import { spawn } from 'child_process';
    import { join } from 'path';
    import { getAgentObservations } from './util/observations.js';
    import { log } from './util/logger.js';
    import { connectRequiredTools } from './util/mcp.js';
    import { DEEBO_ROOT } from './index.js';
    import { updateMemoryBank } from './util/membank.js';
    import { getProjectId } from './util/sanitize.js';
    // import OpenAI from 'openai'; // Removed
    import { ChatCompletionMessageParam, ChatCompletionMessage } from 'openai/resources/chat/completions';
    import { createScenarioBranch } from './util/branch-manager.js';
    import { callLlm, getMotherAgentPrompt } from './util/agent-utils.js'; // Updated import

    const MAX_RUNTIME = 60 * 60 * 1000; // 60 minutes
    const SCENARIO_TIMEOUT = 5 * 60 * 1000;
    const useMemoryBank = process.env.USE_MEMORY_BANK === 'true';

    // Removed safeAssistantMessage function as it's no longer needed with callLlm

    // Mother agent main loop
    export async function runMotherAgent(
      sessionId: string,
      error: string,
      context: string,
      language: string,
      filePath: string,
      repoPath: string,
      signal: AbortSignal, // Added: Cancellation signal
      scenarioPids: Set<number> // Added: Set to track scenario PIDs
    ) {
      await log(sessionId, 'mother', 'info', 'Mother agent started', { repoPath });
      const projectId = getProjectId(repoPath);
      let scenarioCounter = 0; // Simple counter for unique scenario IDs within the session
      const startTime = Date.now();
      const memoryBankPath = join(DEEBO_ROOT, 'memory-bank', projectId);
      let lastObservationCheck = 0;

      try {
        // OBSERVE: Setup tools and LLM Client
        await log(sessionId, 'mother', 'info', 'OODA: observe', { repoPath });
        const { gitClient, filesystemClient } = await connectRequiredTools('mother', sessionId, repoPath);

        // Read LLM configuration from environment variables
        const motherProvider = process.env.MOTHER_HOST; // Read provider name from MOTHER_HOST
        const motherModel = process.env.MOTHER_MODEL;
        const openrouterApiKey = process.env.OPENROUTER_API_KEY;
        const openaiApiKey = process.env.OPENAI_API_KEY;
        const openaiBaseUrl = process.env.OPENAI_BASE_URL;
        const geminiApiKey = process.env.GEMINI_API_KEY;
        const anthropicApiKey = process.env.ANTHROPIC_API_KEY;

        // Create the config object to pass to callLlm
        const llmConfig = {
          provider: motherProvider,
          model: motherModel,
          apiKey: openrouterApiKey,
          openrouterApiKey: openrouterApiKey,
          openaiApiKey: openaiApiKey,
          baseURL: openaiBaseUrl,
          geminiApiKey: geminiApiKey,
          anthropicApiKey: anthropicApiKey
        };

        // Initial conversation context
        const messages: ChatCompletionMessageParam[] = [{
          role: 'assistant',
          content: getMotherAgentPrompt(useMemoryBank, memoryBankPath)
        }, {
          role: 'user',
          content: `Error: ${error}
    Context: ${context}
    Language: ${language}
    File: ${filePath}
    Repo: ${repoPath}
    Session: ${sessionId}
    Project: ${projectId}
    ${useMemoryBank ? '\nPrevious debugging attempts and context are available in the memory-bank directory if needed.' : ''}

    IMPORTANT: Generate your first hypothesis within 2-3 responses. Don't wait for perfect information.`
        }];

    // Check for new observations
    let observations = await getAgentObservations(repoPath, sessionId, 'mother'); // Changed const to let
    if (observations.length > 0) {
      messages.push(...observations.map(obs => ({
        role: 'user' as const,
        content: `Scientific observation: ${obs}`
      })));
    }

    // Initial LLM call using the new utility function with config
    await log(sessionId, 'mother', 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath });
    let replyText = await callLlm(messages, llmConfig);
    if (!replyText) {
      messages.push({ role: 'user', content: 'LLM returned empty or malformed response' });
      await log(sessionId, 'mother', 'warn', 'Received empty/malformed response from LLM', { provider: llmConfig.provider, model: llmConfig.model, repoPath });
    } else {
      // Add the valid response to messages history
      messages.push({ role: 'assistant', content: replyText });
      await log(sessionId, 'mother', 'debug', 'Received from LLM', { response: { content: replyText }, repoPath });
    }

    // ORIENT: Begin investigation loop
    await log(sessionId, 'mother', 'info', 'OODA: orient', { repoPath });

    // Loop while the last reply exists, doesn't contain the solution tag, AND cancellation hasn't been requested
    while (replyText && !replyText.includes('<solution>') && !signal.aborted) { // Check signal in loop condition
      if (Date.now() - startTime > MAX_RUNTIME) {
        await log(sessionId, 'mother', 'warn', 'Investigation exceeded maximum runtime', { repoPath });
        throw new Error('Investigation exceeded maximum runtime');
      }

      // Check for cancellation signal before processing response
      if (signal.aborted) {
        await log(sessionId, 'mother', 'info', 'Cancellation signal received, stopping loop.', { repoPath });
        break; // Exit loop if cancelled
      }

      // The assistant's response (replyText) is already added to messages before the loop starts and after each LLM call inside the loop.

      // Use the latest replyText directly
      const responseText = replyText;

      // Handle MULTIPLE MCP tools (if any) - Parsing from responseText
      const toolCalls = responseText.match(/<use_mcp_tool>[\s\S]*?<\/use_mcp_tool>/g) || [];

      const parsedCalls = toolCalls.map((tc: string) => {
        try {
          const server = tc.includes('git-mcp') ? gitClient! : filesystemClient!;
          const toolMatch = tc.match(/<tool_name>(.*?)<\/tool_name>/);
          if (!toolMatch || !toolMatch[1]) throw new Error('Missing tool');
          const tool = toolMatch[1]!;

          const argsMatch = tc.match(/<arguments>(.*?)<\/arguments>/s);
          if (!argsMatch || !argsMatch[1]) throw new Error('Missing arguments');
          const args = JSON.parse(argsMatch[1]!);

          return { server, tool, args };
        } catch (err) {
          return { error: err instanceof Error ? err.message : String(err) };
        }
      });

      // Process each parsed call
      for (const parsed of parsedCalls) {
        if ('error' in parsed) {
          messages.push({
            role: 'user',
            content: `One of your tool calls was malformed and skipped. Error: ${parsed.error}`
          });
          continue;
        }

        try {
          const result = await parsed.server.callTool({ name: parsed.tool, arguments: parsed.args });
          messages.push({
            role: 'user',
            content: JSON.stringify(result)
          });
        } catch (err) {
          messages.push({
            role: 'user',
            content: `Tool call failed: ${err instanceof Error ? err.message : String(err)}`
          });
        }
      }


      // Handle Hypotheses → Scenario agents - Parsing from responseText
      if (responseText.includes('<hypothesis>')) {
        const hypotheses = [...responseText.matchAll(/<hypothesis>([\s\S]*?)<\/hypothesis>/g)].map(match => match[1].trim());

        if (useMemoryBank) {
          await updateMemoryBank(projectId, `==================
AUTOMATED HYPOTHESIS RECORD
Timestamp: ${new Date().toISOString()}
Error: ${error || 'No error provided'}

${responseText}

==================
`, 'activeContext');
        }

        const scenarioPromises = hypotheses.map(async (hypothesis: string) => {
          const scenarioId = `${sessionId}-${scenarioCounter++}`; // Use counter for unique ID

          await new Promise(resolve => setTimeout(resolve, 100)); // Small delay
          const branchName = await createScenarioBranch(repoPath, scenarioId); // Branch name generation

          const scenarioArgs = [ // Define args for spawn
            join(DEEBO_ROOT, 'build/scenario-agent.js'),
            '--id', scenarioId,
            '--session', sessionId,
            '--error', error,
            '--context', context,
            '--hypothesis', hypothesis,
            '--language', language,
            '--file', filePath || '',
            '--repo', repoPath,
            '--branch', branchName
          ];

          const child = spawn('node', scenarioArgs, {
               cwd: repoPath,             // ensure all file‑based tools run in the repo root
               env: { ...process.env }    // explicitly pass the full Deebo env (incl. DEEBO_NPX_PATH)
             });
          let output = '';

          // Track the PID in the shared Set
          if (child.pid) {
            scenarioPids.add(child.pid);
            await log(sessionId, 'mother', 'info', `Spawned Scenario ${scenarioId} with PID ${child.pid}`, { repoPath, hypothesis, args: scenarioArgs });
          } else {
             await log(sessionId, 'mother', 'warn', `Spawned Scenario ${scenarioId} but PID was unavailable`, { repoPath, hypothesis, args: scenarioArgs });
          }

          child.stdout.on('data', data => output += data);
          child.stderr.on('data', data => output += data);

          // Wait for process exit OR timeout
          return new Promise<string>((resolve) => {
              let resolved = false;
              const scenarioPid = child.pid; // Capture PID for cleanup logic

              // Function to handle cleanup and resolution
              const cleanupAndResolve = (exitInfo: string) => {
                if (resolved) return;
                resolved = true;
                if (scenarioPid) {
                  scenarioPids.delete(scenarioPid); // Remove PID from registry
                  log(sessionId, 'mother', 'debug', `Removed scenario PID ${scenarioPid} from registry`, { repoPath });
                }
                output += `\n${exitInfo}`;
                resolve(output);
              };

              // Handle process exit
              child.on('exit', (code, signal) => {
                cleanupAndResolve(`Scenario ${scenarioId} (PID: ${scenarioPid}) exited with code ${code}, signal ${signal}`);
              });

              // Handle process spawn errors
              child.on('error', err => {
                if (resolved) return;
                resolved = true;
                output += `\nProcess spawn error: ${err}`;
                resolve(output); // Resolve immediately on spawn error
              });

              // Capture stream-level errors (don't resolve promise)
              child.stdout.on('error', err => { output += `\nStdout error: ${err}`; });
              child.stderr.on('error', err => { output += `\nStderr error: ${err}`; });

              // Set a timeout for the scenario
              const timeoutHandle = setTimeout(() => {
                 if (!resolved) {
                    child.kill(); // Force kill the scenario on timeout
                    cleanupAndResolve(`Scenario ${scenarioId} (PID: ${scenarioPid}) timed out after ${SCENARIO_TIMEOUT / 1000}s`);
                 }
              }, SCENARIO_TIMEOUT);

              // Clear timeout if process exits or errors first
              child.on('exit', () => clearTimeout(timeoutHandle));
              child.on('error', () => clearTimeout(timeoutHandle));
            });
        });

        // Wait for all spawned scenarios for this turn to complete
        const scenarioOutputs = await Promise.all(scenarioPromises);

        messages.push({ role: 'user', content: scenarioOutputs.join('\n\n---\n\n') }); // Add separator for readability
      }

      // Mother can optionally edit memory bank directly via filesystem-mcp. No forced writes.

      // Check for new observations before each Claude call
      const newObservations = await getAgentObservations(repoPath, sessionId, 'mother');
      if (newObservations.length > observations.length) {
        const latestObservations = newObservations.slice(observations.length);
        messages.push(...latestObservations.map(obs => ({
          role: 'user' as const,
          content: `Scientific observation: ${obs}`
        })));
        observations = newObservations; // Update the baseline observation list
      }

      // Check for cancellation signal again before the next LLM call
      if (signal.aborted) {
        await log(sessionId, 'mother', 'info', 'Cancellation signal received before next LLM call.', { repoPath });
        break; // Exit loop if cancelled
      }

      // Make next LLM call using the new utility function with config
      await log(sessionId, 'mother', 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath });
      replyText = await callLlm(messages, llmConfig); // Update replyText
      if (!replyText) {
        messages.push({ role: 'user', content: 'LLM returned empty or malformed response' });
        await log(sessionId, 'mother', 'warn', 'Received empty/malformed response from LLM', { provider: llmConfig.provider, model: llmConfig.model, repoPath });
        // replyText is already falsy, loop will terminate naturally
      } else {
        // Add the valid response to messages history
        messages.push({ role: 'assistant', content: replyText });
        await log(sessionId, 'mother', 'debug', 'Received from LLM', { response: { content: replyText }, provider: llmConfig.provider, model: llmConfig.model, repoPath });
      }

      await new Promise(resolve => setTimeout(resolve, 1000));
    }

    // Determine final status based on whether loop was aborted or completed naturally
    let finalStatusMessage: string;
    if (signal.aborted) {
      finalStatusMessage = 'Session cancelled by user request.';
      await log(sessionId, 'mother', 'info', finalStatusMessage, { repoPath });
    } else if (replyText?.includes('<solution>')) {
      finalStatusMessage = 'Solution found or investigation concluded.';
      await log(sessionId, 'mother', 'info', finalStatusMessage, { repoPath });
    } else {
      finalStatusMessage = 'Loop terminated unexpectedly (e.g., LLM error).';
       await log(sessionId, 'mother', 'warn', finalStatusMessage, { repoPath });
    }

    const finalContent = replyText || finalStatusMessage; // Use last reply or status message

    // Structured record at the end
    if (useMemoryBank) {
      await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - ${new Date().toISOString()}
${error ? `Initial Error: ${error}` : ''}
Final Status: ${finalStatusMessage}
${finalContent.includes('<solution>') ? finalContent : `Last Response/Status: ${finalContent}`}
Scenarios Spawned: ${scenarioCounter}
Duration: ${Math.round((Date.now() - startTime) / 1000)}s`, 'progress');
    }

    return finalContent; // Return the last reply or status

  } catch (err) {
    const caughtError = err instanceof Error ? err : new Error(String(err));
    // Check if the error was due to cancellation signal during an operation
     if (signal.aborted) {
       await log(sessionId, 'mother', 'info', `Operation aborted during execution: ${caughtError.message}`, { repoPath });
       // Optionally update progress log for aborted state
       if (useMemoryBank) {
         await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - ABORTED - ${new Date().toISOString()}\nError during abort: ${caughtError.message}`, 'progress');
       }
       return 'Session cancelled during operation.'; // Return specific cancellation message
     } else {
       // Log and record other errors
       await log(sessionId, 'mother', 'error', `Failed: ${caughtError.message}`, { repoPath, stack: caughtError.stack });
       if (useMemoryBank) {
         await updateMemoryBank(projectId, `\n## Debug Session ${sessionId} - FAILED - ${new Date().toISOString()}\nError: ${caughtError.message}\nStack: ${caughtError.stack}`, 'progress');
       }
       throw caughtError; // Re-throw unexpected errors
     }
  } finally {
     // Ensure any remaining scenario PIDs are cleaned up if the mother agent exits unexpectedly
     // (though the 'exit' handler should cover most cases)
     if (scenarioPids.size > 0) {
       await log(sessionId, 'mother', 'warn', `Mother agent exiting with ${scenarioPids.size} scenario PIDs still in registry.`, { repoPath, pids: Array.from(scenarioPids) });
       // Optionally attempt to kill them here, though 'cancel' is the primary mechanism
     }
  }
}

=== src/index.ts ===

import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
import { readFile, mkdir, readdir, access, writeFile } from 'fs/promises';
import { config } from 'dotenv';
import { dirname, join } from 'path';
import * as path from 'path';
import { fileURLToPath } from 'url';
import { runMotherAgent } from './mother-agent.js';
import { getProjectId } from './util/sanitize.js';
import { writeObservation } from './util/observations.js';
import { exec, spawn, ChildProcess } from 'child_process';
import { promisify } from 'util';
import { homedir } from "node:os";

const execPromise = promisify(exec);

function winRoamingBin(): string {
  // VS Code spawns MCP servers with a clean env (no APPDATA)
  const base = process.env.APPDATA ?? path.join(homedir(), "AppData", "Roaming");
  return path.join(base, "npm");
}

// Function to find tool paths during initialization
async function findToolPaths() {
  const isWindows = process.platform === 'win32';
  
  let npxPath, uvxPath;

  if (isWindows) {
    try {
      const npxPaths = (await execPromise('cmd.exe /c where npx.cmd')).stdout.trim().split('\n');
      // Favor Program Files to get direct executable
      const foundNpxPath = npxPaths.find(p => p.includes('Program Files'));
      if (!foundNpxPath) {
        throw new Error('Could not find npx.cmd in Program Files');
      }
      npxPath = path.normalize(foundNpxPath).trim();

      uvxPath = path.normalize((await execPromise('cmd.exe /c where uvx.exe')).stdout.trim().split('\n')[0]).trim();
    } catch (err) {
      throw new Error(`Failed to find tool paths: ${err}`);
    }
  }else {
    npxPath = (await execPromise('which npx')).stdout.trim();
    uvxPath = (await execPromise('which uvx')).stdout.trim();
  }

  // Store normalized paths
  process.env.DEEBO_NPX_PATH = npxPath;
  process.env.DEEBO_UVX_PATH = uvxPath;

  // Get npm bin directory for Windows desktop-commander.cmd
  const npmBin = isWindows
    ? winRoamingBin()                                  // Use homedir() when VS Code strips env
    : path.dirname(npxPath);                           // same folder as npx on *nix

  process.env.DEEBO_NPM_BIN = npmBin;                 // <-- expose for later
  
  return { npxPath, uvxPath, npmBin };
}

// Helper to find session directory
async function findSessionDir(sessionId: string): Promise<string | null> {
  const memoryBank = join(DEEBO_ROOT, 'memory-bank');
  const projects = await readdir(memoryBank);
  
  for (const project of projects) {
    const sessionPath = join(memoryBank, project, 'sessions', sessionId);
    try {
      await access(sessionPath);
      return sessionPath;
    } catch {
      continue;
    }
  }
  return null;
}

// Registry to track active sessions and their associated processes/controllers
const processRegistry = new Map<string, {
  motherController: AbortController;
  scenarioPids: Set<number>; // Store PIDs of spawned scenario agents
}>();

// Track terminated PIDs across all tools
const terminatedPids = new Set<number>();

// Load environment variables from .env file
config();

// Validate required environment variables
if (!process.env.MOTHER_MODEL) {
  throw new Error('MOTHER_MODEL environment variable is required');
}
if (!process.env.SCENARIO_MODEL) {
  throw new Error('SCENARIO_MODEL environment variable is required');
}


// Set up basic directories
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
export const DEEBO_ROOT = join(__dirname, '..');

// Create required directories
await mkdir(join(DEEBO_ROOT, 'memory-bank'), { recursive: true });

// Find and configure tool paths
await findToolPaths();

// Create MCP server
const server = new McpServer({
 name: "Deebo",
 version: "1.0.0"
});

// Register start tool - begins a debug session
server.tool(
  "start",
  "Begins an autonomous debugging session that investigates software bugs through multiple competing hypotheses. This tool launches a mother agent that analyzes errors, generates diverse hypotheses about potential causes, and spawns isolated scenario agents to test each hypothesis in separate git branches. The mother agent coordinates the investigation, evaluates scenario reports, and synthesizes a validated solution when sufficient evidence is found.",
  {
    error: z.string().describe("The error message or description of the bug to investigate"),
    repoPath: z.string().describe("Absolute path to the git repository containing the code to debug"),
    context: z.string().optional().describe("Additional context like code snippets, previous attempts, or relevant information"),
    language: z.string().optional().describe("Programming language of the code being debugged (e.g., 'typescript', 'python')"),
    filePath: z.string().optional().describe("Relative path to the specific file containing the bug, if known")
  },
  async ({ error, repoPath, context, language, filePath }, extra) => {
    const projectId = getProjectId(repoPath);
    const sessionId = `session-${Date.now()}`;
    await mkdir(join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'logs'), { recursive: true });
    await mkdir(join(DEEBO_ROOT, 'memory-bank', projectId, 'sessions', sessionId, 'reports'), { recursive: true });

    // Create controller and PID set for this session
    const motherController = new AbortController();
    const scenarioPids = new Set<number>();

    // Register the session
    processRegistry.set(sessionId, {
      motherController,
      scenarioPids
    });
    // console.log(`Registered session ${sessionId}`); // Removed informational log

    // Run mother agent in background, passing the signal and PID set
    // Note: runMotherAgent signature needs to be updated in mother-agent.ts to accept these
    runMotherAgent(
      sessionId,
      error,
      context ?? "",
      language ?? "typescript",
      filePath ?? "",
      repoPath,
      motherController.signal, // Pass the signal
      scenarioPids // Pass the Set for tracking scenario PIDs
    ).catch(err => {
      console.error(`Debug session ${sessionId} failed during execution:`, err);
      // Clean up registry if mother agent fails during execution
      processRegistry.delete(sessionId);
    }).finally(() => {
      // Optional: Could also remove from registry on normal completion,
      // but cancel needs to handle the case where it's still running.
      // For now, only removing on error/cancel.
      // console.log(`Mother agent promise settled for session ${sessionId}.`); // Removed internal log
    });

    // Return session ID immediately
    return {
      content: [{
        type: "text",
        text: sessionId
      }]
    };
  }
);

// Register check tool - gets status of a debug session
server.tool(
  "check",
  "Retrieves the current status of a debugging session, providing a detailed pulse report. For in-progress sessions, the pulse includes the mother agent's current stage in the OODA loop, running scenario agents with their hypotheses, and any preliminary findings. For completed sessions, the pulse contains the final solution with a comprehensive explanation, relevant code changes, and outcome summaries from all scenario agents that contributed to the solution. Use this tool to monitor ongoing progress or retrieve the final validated fix.",
  {
    sessionId: z.string().describe("The session ID returned by the start tool when the debugging session was initiated")
  },
  async ({ sessionId }, extra) => {
    try {
      const sessionDir = await findSessionDir(sessionId);
      if (!sessionDir) {
        return {
          content: [{ 
            type: "text",
            text: `Session ${sessionId} not found`
          }]
        };
      }

      // Get time metrics and mother status
      const logsDir = join(sessionDir, 'logs');
      const motherLogPath = join(logsDir, 'mother.log');
      const motherLog = await readFile(motherLogPath, 'utf8');
      const motherLines = motherLog.split('\n').filter(Boolean);

      if (!motherLines.length) return { content: [{ type: "text", text: 'Session initializing' }] };

      const firstEvent = JSON.parse(motherLines[0]);
      const durationMs = Date.now() - new Date(firstEvent.timestamp).getTime();

      // Determine status by scanning for solution tag, cancellation, or errors
      let status = 'in_progress'; // Default status
      let solutionFoundInScan = false;
      let lastValidEvent: any = null; // Store the last successfully parsed event
      // Use module-level terminatedPids set

      for (let i = motherLines.length - 1; i >= 0; i--) {
        try {
          const event = JSON.parse(motherLines[i]);
          if (!lastValidEvent) lastValidEvent = event; // Capture the last valid event

          const content = event.data?.response?.content || event.message || '';
          
          // Check for process spawn and termination with comprehensive pattern
          const SCENARIO_PID_PATTERN = /(?:Spawned|Removed|Terminated|Cancelled) Scenario .* PID (\d+)/;
          const pidMatch = content.match(SCENARIO_PID_PATTERN);
          if (pidMatch) {
            const pid = parseInt(pidMatch[1]);
            // Check for any termination-related terms
            if (content.match(/(Removed|Terminated|Cancelled)/)) {
              terminatedPids.add(pid);
            }
          }
          
          // Check for session cancellation
          if (content.includes('Session cancelled by user request')) {
            status = 'cancelled';
            break;
          }
          
          // Check for solution
          if (content.includes('<solution>')) {
            status = 'completed';
            solutionFoundInScan = true;
            break;
          }
          
          // Check for error status
          if (event.level === 'error') {
            status = 'failed';
            // Continue scanning for potential solution or cancellation
          }
        } catch (e) {
          // Skip invalid JSON lines
          continue;
        }
      }

      // If status is still 'in_progress' after scan, check the last valid event's level
      if (status === 'in_progress' && lastValidEvent && lastValidEvent.level === 'error') {
        status = 'failed';
      }

      // Helper functions for PID mapping and status
      function buildScenarioPIDMapping(motherLines: string[]): Map<string, number> {
        const mapping = new Map<string, number>();
        for (const line of motherLines) {
          try {
            const event = JSON.parse(line);
            const message = event.message || '';
            const matches = message.match(/Spawned Scenario ([^ ]+) with PID (\d+)/);
            if (matches) {
              const [_, scenarioId, pidStr] = matches;
              mapping.set(scenarioId, parseInt(pidStr));
            }
          } catch (e) {
            continue;
          }
        }
        return mapping;
      }

      function getScenarioStatus(scenarioId: string, pidMapping: Map<string, number>): string {
        const pid = pidMapping.get(scenarioId);
        if (!pid) return 'Unknown';
        return terminatedPids.has(pid) ? 'Terminated' : 'Running';
      }

      // Build PID mapping from mother log
      const pidMapping = buildScenarioPIDMapping(motherLines);

      // Count scenario statuses
      const reportsDir = join(sessionDir, 'reports');
      const scenarioLogs = await readdir(logsDir);
      const reportFiles = await readdir(reportsDir);
      
      // Count scenarios by status
      let runningCount = 0;
      let terminatedCount = 0;
      let reportedCount = reportFiles.length;

      // Check each scenario's status using the PID mapping
      for (const logFile of scenarioLogs.filter(f => f.startsWith('scenario-'))) {
        const scenarioId = logFile.replace('scenario-', '').replace('.log', '');
        const status = getScenarioStatus(scenarioId, pidMapping);
        
        if (status === 'Terminated') {
          terminatedCount++;
        } else if (!reportFiles.includes(scenarioId + '.json')) {
          runningCount++;
        }
      }

      // Build the pulse
      let pulse = `=== Deebo Session Pulse: ${sessionId} ===\n`;
      pulse += `Timestamp: ${new Date().toISOString()}\n`;
      pulse += `Overall Status: ${status}\n`;
      pulse += `Session Duration: ${Math.floor(durationMs / 1000)}s\n\n`;

      pulse += `--- Mother Agent ---\n`;
      pulse += `Status: ${status === 'in_progress' ? 'working' : status}\n`;
      pulse += `Last Activity: ${lastValidEvent ? lastValidEvent.timestamp : 'N/A'}\n`;

      // Update summary line to include terminated count
      pulse += `--- Scenario Agents (${scenarioLogs.filter(f => f.startsWith('scenario-')).length} Total: ${runningCount} Running, ${terminatedCount} Terminated, ${reportedCount} Reported) ---\n\n`;

      // For completed sessions, find and show solution
      if (status === 'completed') {
        // Look for solution in mother log
        let foundSolution = false;
        
        // Scan backwards for efficiency (newer entries more likely to have solution)
        for (let i = motherLines.length - 1; i >= 0; i--) {
          try {
            const line = motherLines[i];
            const event = JSON.parse(line);
            const content = event.data?.response?.content || event.message || '';
            
            // Check for solution tag in content string
            if (content.includes('<solution>')) {
              const match = content.match(/<solution>([\s\S]*?)<\/solution>/);
              if (match && match[1]) {
                pulse += `MOTHER SOLUTION:\n`;
                pulse += `<<<<<<< SOLUTION\n`;
                pulse += match[1].trim() + '\n';
                pulse += `======= SOLUTION END >>>>>>>\n\n`;
                foundSolution = true;
                break;
              }
            }
          } catch (e) {
            // Skip invalid JSON lines
            continue;
          }
        }
        
        // No solution found message
        if (!foundSolution) {
          pulse += `STATUS COMPLETE BUT NO SOLUTION TAG FOUND IN LOGS\n`;
          pulse += `Check the mother.log file for more details.\n\n`;
        }
      } else if (status === 'in_progress' || status === 'failed') {
        // For in-progress or failed, show last known stage or last message
        let stageMessage = 'No stage information found.';
        if (lastValidEvent) { // Use the last valid event captured during status scan
             stageMessage = lastValidEvent.message || JSON.stringify(lastValidEvent.data); // Show message or data
             if (lastValidEvent.message && lastValidEvent.message.includes('OODA:')) {
                 pulse += `Last Stage: ${lastValidEvent.message}\n\n`;
             } else {
                 pulse += `Last Log Message: ${stageMessage.substring(0, 100)}${stageMessage.length > 100 ? '...' : ''}\n\n`;
             }
        } else {
             pulse += `Last Stage: ${stageMessage}\n\n`;
        }

      }


      // Process reported scenarios
      for (const file of reportFiles) {
        const scenarioId = file.replace('.json', '');
        
        const scenarioLogPath = join(logsDir, `scenario-${scenarioId}.log`);
        let scenarioLog;
        try {
          scenarioLog = await readFile(scenarioLogPath, 'utf8');
        } catch (e) {
          continue; // Skip if log file doesn't exist
        }
        
        const scenarioLines = scenarioLog.split('\n').filter(Boolean);
        if (!scenarioLines.length) continue;

        // Get hypothesis - scan once
        let hypothesis = 'Unknown hypothesis';
        for (let i = 0; i < scenarioLines.length; i++) {
          try {
            const event = JSON.parse(scenarioLines[i]);
            if (event.data?.hypothesis) {
              hypothesis = event.data.hypothesis;
              break;
            }
          } catch (e) {
            continue;
          }
        }

        pulse += `* Scenario: ${scenarioId}\n`;
        pulse += `  Status: Reported\n`;

        if (status === 'completed') {
          // Show summary for completed scenarios in completed sessions
          try {
            const reportRaw = await readFile(join(reportsDir, `${scenarioId}.json`), 'utf8');
            const report = JSON.parse(reportRaw);
            
            // Extract key information from report
            const reportStr = typeof report === 'string' ? report : JSON.stringify(report, null, 2);
            const lines = reportStr.split('\n');
            
            // Find CONFIRMED status and INVESTIGATION section
            let confirmed = 'Unknown';
            let investigationLines: string[] = [];
            let inInvestigation = false;
            
            for (let i = 0; i < lines.length; i++) {
              const line = lines[i].trim();
              if (line.startsWith('CONFIRMED:')) {
                confirmed = line.split(':')[1].trim();
              }
              if (line === 'INVESTIGATION:') {
                inInvestigation = true;
                continue;
              }
              if (inInvestigation && line && !line.startsWith('CONCLUSION:')) {
                investigationLines.push(line);
              }
              if (line.startsWith('CONCLUSION:')) {
                break;
              }
            }
            
            pulse += `  Outcome Summary:\n`;
            pulse += `  <<<<<<< OUTCOME ${scenarioId}\n`;
            pulse += `  HYPOTHESIS: ${hypothesis}\n\n`;
            pulse += `  CONFIRMED: ${confirmed}\n\n`;
            if (investigationLines.length > 0) {
              pulse += `  INVESTIGATION:\n`;
              pulse += `  ${investigationLines.join('\n  ')}\n`;
            }
            pulse += `  ======= OUTCOME ${scenarioId} END >>>>>>>\n`;
          } catch (e) {
            const error = e as Error;
            pulse += `  Error reading report: ${error.message}\n`;
          }
        }

        pulse += `  (Full report: ${join(reportsDir, `${scenarioId}.json`)})\n\n`;
      }

      // Process unreported scenarios (either running or terminated without report)
      const unreportedScenarios = scenarioLogs
        .filter(f => f.startsWith('scenario-'))
        .filter(f => !reportFiles.includes(f.replace('scenario-', '').replace('.log', '.json')));
      
      for (const file of unreportedScenarios) {
        const scenarioId = file.replace('scenario-', '').replace('.log', '');
        
        let scenarioLog;
        try {
          scenarioLog = await readFile(join(logsDir, file), 'utf8');
        } catch (e) {
          continue; // Skip if log file doesn't exist
        }
        
        const scenarioLines = scenarioLog.split('\n').filter(Boolean);
        if (!scenarioLines.length) continue;

        // Get hypothesis and events from scenario log
        let hypothesis = 'Unknown hypothesis';
        let firstEvent, lastEvent;
        
        try {
          // Extract hypothesis and events
          for (const line of scenarioLines) {
            try {
              const event = JSON.parse(line);
              if (event.data?.hypothesis) {
                hypothesis = event.data.hypothesis;
              }
              if (!firstEvent) firstEvent = event;
              lastEvent = event;
            } catch (e) {
              continue;
            }
          }

          // Calculate runtime and add to pulse
          const runtime = Math.floor((Date.now() - new Date(firstEvent.timestamp).getTime()) / 1000);
          pulse += `* Scenario: ${scenarioId}\n`;
          pulse += `  Status: ${getScenarioStatus(scenarioId, pidMapping)}\n`;
          pulse += `  Hypothesis: "${hypothesis}"\n`;
          pulse += `  Runtime: ${runtime}s\n`;
          pulse += `  Latest Activity: ${lastEvent.message}\n`;
          pulse += `  (Log: ${join(logsDir, file)})\n\n`;
        } catch (e) {
          // Skip scenarios with invalid JSON
          continue;
        }
      }

      pulse += `--- End Session Pulse ---`;

      return {
        content: [{ 
          type: "text",
          text: pulse
        }]
      };

    } catch (err) {
      return {
        content: [{ 
          type: "text",
          text: `Error generating pulse: ${err}`
        }]
      };
    }
  }
);

server.tool(
  "cancel",
  "Terminates all processes related to a debugging session. This will stop the mother agent and all scenario agents, releasing system resources. Use this when you have your solution or want to abandon the debugging process.",
  {
    sessionId: z.string().describe("The session ID returned by the start tool when the debugging session was initiated")
  },
  async ({ sessionId }, extra) => {
    // No need to sanitize ID when using the registry Map key
    const sessionEntry = processRegistry.get(sessionId);

    if (!sessionEntry) {
      return {
        content: [{
          type: "text",
          text: `Session ${sessionId} not found in registry. It might have already completed or failed.`
        }]
      };
    }

    const { motherController, scenarioPids } = sessionEntry;
    let killedScenarios = 0;
    let failedKills = 0;

    try {
      // 1. Signal the Mother agent to stop its loop cooperatively
      // console.log(`Signaling Mother Agent for session ${sessionId} to stop.`); // Removed informational log
      motherController.abort();

      // 2. Terminate any tracked Scenario agent processes
      // console.log(`Terminating ${scenarioPids.size} tracked Scenario Agents for session ${sessionId}.`); // Removed informational log
      for (const pid of scenarioPids) {
        try {
          // Use SIGTERM first for graceful shutdown
          process.kill(pid, 'SIGTERM');
          killedScenarios++;
          terminatedPids.add(pid); // Add to terminated set right away
          // console.log(`Sent SIGTERM to scenario PID ${pid}`); // Removed informational log
        } catch (err: any) {
          // Ignore errors if process is already gone (e.g., ESRCH)
          if (err.code !== 'ESRCH') {
            // console.warn(`Failed to send SIGTERM to scenario PID ${pid}: ${err.message}`); // Removed console.warn
            failedKills++;
          } else {
            // Process already gone
            terminatedPids.add(pid); // Still mark as terminated if process is already gone
          }
        }
      }

      // Optional: Add a short delay and SIGKILL survivors if needed.
      // For simplicity, we'll rely on SIGTERM for now.

      // 3. Clean up the registry entry *after* attempting kills
      processRegistry.delete(sessionId);
      // console.log(`Removed session ${sessionId} from process registry.`); // Removed informational log

      return {
          content: [{
            type: "text",
            text: `Cancellation request sent for session ${sessionId}:\n` +
                  `- Mother agent signaled to stop.\n` +
                  `- Targeted ${killedScenarios} scenario processes (includes already exited).\n` +
                  `- ${failedKills} termination signals failed (excluding already exited).`
          }]
        };

      } catch (err: any) {
        // Handle potential errors during the cancellation process itself
        const errorMessage = err.message || String(err);
        // console.error(`Error during cancellation for session ${sessionId}: ${errorMessage}`); // Removed console.error
        // Attempt to clean up registry even if cancellation had issues
        processRegistry.delete(sessionId); // Ensure cleanup
        return {
          content: [{
            type: "text",
            text: `Error during cancellation for session ${sessionId}: ${errorMessage}. Registry entry removed.`
          }]
        };
      }
    }
  );

// Register add_observation tool
server.tool(
  "add_observation",
  "Adds an external observation to an agent in the debugging session. This allows other tools or human insights to be incorporated into the ongoing investigation. Observations are logged and considered by the agent in subsequent reasoning steps.",
  {
    agentId: z.string(),
    observation: z.string(),
    sessionId: z.string()
  },
  async ({ agentId, observation, sessionId }, extra) => {
    try {
      // Get session directory
      const sessionDir = await findSessionDir(sessionId);
      if (!sessionDir) {
        throw new Error('Session not found');
      }

      // Get repoPath from agent log
      const logFile = join(sessionDir, 'logs', `${agentId}.log`);
      const agentLog = await readFile(logFile, 'utf8');
      const firstLine = agentLog.split('\n')[0];
      const firstEvent = JSON.parse(firstLine);
      const repoPath = firstEvent.data?.repoPath;

      if (!repoPath) {
        throw new Error('Could not find repoPath in agent log');
      }

      await writeObservation(repoPath, sessionId, agentId, observation);
      return {
        content: [{
          type: "text",
          text: "Observation logged"
        }]
      };
    } catch (err) {
      throw new Error(`Observation write failed: ${err instanceof Error ? err.message : String(err)}`);
    }
  }
);

// Connect transport
const transport = new StdioServerTransport();
await server.connect(transport);

=== src/scenario-agent.ts ===

import { log } from './util/logger.js';
import { connectRequiredTools } from './util/mcp.js';
import { writeReport } from './util/reports.js';  // System infrastructure for capturing output
// import OpenAI from 'openai'; // Removed
import { ChatCompletionMessageParam, ChatCompletionMessage } from 'openai/resources/chat/completions';
import { writeObservation, getAgentObservations } from './util/observations.js';
import { callLlm, getScenarioAgentPrompt } from './util/agent-utils.js'; // Updated import

const MAX_RUNTIME = 15 * 60 * 1000; // 15 minutes

// Define LlmConfig interface (can be moved to a shared types file later if needed)
interface LlmConfig {
  provider?: string;
  model?: string;
  maxTokens?: number;
  apiKey?: string; // Generic key, primarily used for OpenRouter for backward compatibility
  openrouterApiKey?: string; // Alias for apiKey, prefer this for new code
  baseURL?: string; // For OpenAI-compatible APIs
  openaiApiKey?: string; // For OpenAI and compatible providers
  geminiApiKey?: string;
  anthropicApiKey?: string;
}

interface ScenarioArgs {
  id: string;
  session: string;
  error: string;
  context: string;
  hypothesis: string;
  language: string;
  repoPath: string;
  filePath?: string;
  branch: string;
}

function parseArgs(args: string[]): ScenarioArgs {
  const result: Record<string, string> = {};
  for (let i = 0; i < args.length; i++) {
    if (args[i].startsWith('--')) {
      const key = args[i].slice(2);
      const value = args[i + 1] && !args[i + 1].startsWith('--') ? args[i + 1] : '';
      result[key] = value;
      if (value) i++;
    }
  }

  const repoPath = result.repo;
  if (!repoPath) {
    throw new Error('Required argument missing: --repo');
  }

  return {
    id: result.id || '',
    session: result.session || '',
    error: result.error || '',
    context: result.context || '',
    hypothesis: result.hypothesis || '',
    language: result.language || 'typescript',
    repoPath,
    filePath: result.file || undefined,
    branch: result.branch || ''
  };
}

export async function runScenarioAgent(args: ScenarioArgs) {
  await log(args.session, `scenario-${args.id}`, 'info', 'Scenario agent started', { repoPath: args.repoPath, hypothesis: args.hypothesis });
  await log(
    args.session,
    `scenario-${args.id}`,
    'debug',
    `CWD: ${process.cwd()}, DEEBO_NPX_PATH=${process.env.DEEBO_NPX_PATH}, DEEBO_UVX_PATH=${process.env.DEEBO_UVX_PATH}`,
    { repoPath: args.repoPath }
  );
  try {
    // Set up tools
    await log(args.session, `scenario-${args.id}`, 'info', 'Connecting to tools...', { repoPath: args.repoPath });
  const { gitClient, filesystemClient } = await connectRequiredTools(
    `scenario-${args.id}`,
    args.session,
    args.repoPath
  );
  await log(args.session, `scenario-${args.id}`, 'info', 'Connected to tools successfully', { repoPath: args.repoPath });

    // Branch creation is handled by system infrastructure before this agent is spawned.

    // Start LLM conversation with initial context
    const startTime = Date.now();
    // Initial conversation context
    const messages: ChatCompletionMessageParam[] = [{
      role: 'assistant',
      content: getScenarioAgentPrompt({
        branch: args.branch,
        hypothesis: args.hypothesis,
        context: args.context,
        repoPath: args.repoPath
      })
    }, {
      role: 'user',
      content: `Error: ${args.error}
Context: ${args.context}
Language: ${args.language}
File: ${args.filePath}
Repo: ${args.repoPath}
Hypothesis: ${args.hypothesis}`
    }];

    // Check for observations
    const observations = await getAgentObservations(args.repoPath, args.session, `scenario-${args.id}`);
    if (observations.length > 0) {
      messages.push(...observations.map((obs: string) => ({
        role: 'user' as const,
        content: `Scientific observation: ${obs}`
      })));
    }

    // Read LLM configuration from environment variables
    const scenarioProvider = process.env.SCENARIO_HOST; // Read provider name from SCENARIO_HOST
    const scenarioModel = process.env.SCENARIO_MODEL;
    const openrouterApiKey = process.env.OPENROUTER_API_KEY; // Still needed if provider is 'openrouter'
    const openaiApiKey = process.env.OPENAI_API_KEY;
    const openaiBaseUrl = process.env.OPENAI_BASE_URL;
    const geminiApiKey = process.env.GEMINI_API_KEY;
    const anthropicApiKey = process.env.ANTHROPIC_API_KEY;

    // Create the config object to pass to callLlm
    const llmConfig: LlmConfig = {
      provider: scenarioProvider, // Use the provider name from SCENARIO_HOST
      model: scenarioModel,
      apiKey: openrouterApiKey,
      openrouterApiKey: openrouterApiKey, // For OpenRouter
      openaiApiKey: openaiApiKey, // For OpenAI and compatible providers
      baseURL: openaiBaseUrl, // For OpenAI-compatible APIs
      geminiApiKey: geminiApiKey,
      anthropicApiKey: anthropicApiKey
    };

    await log(args.session, `scenario-${args.id}`, 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath: args.repoPath });
    let replyText = await callLlm(messages, llmConfig);
    if (!replyText) {
      await log(args.session, `scenario-${args.id}`, 'warn', 'Received empty/malformed response from LLM', { repoPath: args.repoPath });
      // Exit if the first call fails, as there's no response to process
      await writeReport(args.repoPath, args.session, args.id, 'Initial LLM call returned empty response.');
      console.log('Initial LLM call returned empty response.');
      process.exit(1);
    } else {
      messages.push({ role: 'assistant', content: replyText });
      await log(args.session, `scenario-${args.id}`, 'debug', 'Received from LLM', { response: { content: replyText }, repoPath: args.repoPath });
    }

    while (true) {
      if (Date.now() - startTime > MAX_RUNTIME) {
        await writeReport(args.repoPath, args.session, args.id, 'Investigation exceeded maximum runtime');
        console.log('Investigation exceeded maximum runtime');
        process.exit(1);
      }

      // The assistant's response (replyText) is already added to messages history
      const responseText = replyText;

      // Check for report FIRST - if found, write it and exit immediately
      // No need to process tool calls if we have a report since they would only be used in the next turn
      const reportMatch = responseText.match(/<report>\s*([\s\S]*?)<\/report>/i);
      if (reportMatch) {
        const reportText = reportMatch[1].trim();
        await writeReport(args.repoPath, args.session, args.id, reportText);
        console.log(reportText);
        process.exit(0);
      }

      // Only process tool calls if we don't have a report
      const toolCalls = responseText.match(/<use_mcp_tool>[\s\S]*?<\/use_mcp_tool>/g) || [];

      const parsedCalls = toolCalls.map((tc: string) => {
        try {
          const server = tc.includes('git-mcp') ? gitClient! : filesystemClient!;
          const toolMatch = tc.match(/<tool_name>(.*?)<\/tool_name>/);
          if (!toolMatch || !toolMatch[1]) throw new Error('Missing tool');
          const tool = toolMatch[1]!;

          const argsMatch = tc.match(/<arguments>(.*?)<\/arguments>/s);
          if (!argsMatch || !argsMatch[1]) throw new Error('Missing arguments');
          const args = JSON.parse(argsMatch[1]!);

          return { server, tool, args };
        } catch (err) {
          return { error: err instanceof Error ? err.message : String(err) };
        }
      });

      // Abort if *any* call fails to parse
      const invalid = parsedCalls.find(p => 'error' in p);
      if (invalid) {
        messages.push({
          role: 'user',
          content: `One of your tool calls was malformed and none were run. Error: ${invalid.error}`
        });
        // No need to clear assistantResponse here, just continue the loop
        continue;
      }

      const validCalls = parsedCalls as { server: NonNullable<typeof gitClient>, tool: string, args: any }[];

      // Only now, execute each one
      for (const { server, tool, args } of validCalls) {
        if (tool === 'git_create_branch') {
          messages.push({
            role: 'user',
            content: 'git_create_branch is not allowed — the branch was already created by the mother agent.'
          });
          continue;
        }

        try {
            const result = await server.callTool({ name: tool, arguments: args });
            messages.push({
              role: 'user',
              content: JSON.stringify(result)
            });
        } catch (toolErr) {
            messages.push({
              role: 'user',
              content: `Tool call failed: ${toolErr instanceof Error ? toolErr.message : String(toolErr)}`
            });
        }
      }

      // Continue the conversation
      // Check for new observations before each Claude call
      const newObservations = await getAgentObservations(args.repoPath, args.session, `scenario-${args.id}`);
      if (newObservations.length > observations.length) {
        const latestObservations = newObservations.slice(observations.length);
        messages.push(...latestObservations.map((obs: string): ChatCompletionMessageParam => ({
          role: 'user', // No 'as const' needed here
          content: `Scientific observation: ${obs}`
        })));
        // Update the baseline observations count after processing
        // This was the bug in the previous attempt - it needs to be updated *outside* the if block
        // observations = newObservations; // Let's remove this line as it wasn't in the original and might be incorrect logic introduced by me. The original logic only checked length difference.
      }

      // Make next LLM call
      await log(args.session, `scenario-${args.id}`, 'debug', 'Sending to LLM', { model: llmConfig.model, provider: llmConfig.provider, messages, repoPath: args.repoPath });
      replyText = await callLlm(messages, llmConfig); // Update replyText
      if (!replyText) {
        await log(args.session, `scenario-${args.id}`, 'warn', 'Received empty/malformed response from LLM', { provider: llmConfig.provider, model: llmConfig.model, repoPath: args.repoPath });
        // If the LLM fails mid-conversation, write a report and exit
        await writeReport(args.repoPath, args.session, args.id, 'LLM returned empty response mid-investigation.');
        console.log('LLM returned empty response mid-investigation.');
        process.exit(1);
      } else {
        messages.push({ role: 'assistant', content: replyText });
        await log(args.session, `scenario-${args.id}`, 'debug', 'Received from LLM', { response: { content: replyText }, provider: llmConfig.provider, model: llmConfig.model, repoPath: args.repoPath });
      }

      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  } catch (error) {
    const errorText = error instanceof Error ? error.message : String(error);
    await writeReport(args.repoPath, args.session, args.id, `SCENARIO ERROR: ${errorText}`);
    console.log(`SCENARIO ERROR: ${errorText}`);
    process.exit(1);
  }
}

// Parse args and run
const args = parseArgs(process.argv);
runScenarioAgent(args).catch(err => {
  const errorText = err instanceof Error ? err.message : String(err);
  console.log(`SCENARIO ERROR: ${errorText}`);
  process.exit(1);
});

=== packages/deebo-setup/src/utils.ts ===

import { homedir } from 'os';
import { join } from 'path';
import { access, mkdir, readFile, writeFile } from 'fs/promises';
import { McpConfig, SetupConfig } from './types.js';
import chalk from 'chalk';
import { simpleGit as createGit } from 'simple-git';
import inquirer from 'inquirer';

export const DEEBO_REPO = 'https://github.com/snagasuri/deebo-prototype.git';

export async function checkPrerequisites(): Promise<void> {
  // Check Node version
  // new (allow ANY major ≥18)
  const nodeVersion = process.version;                     // e.g. "v23.11.0"
  const major = Number(nodeVersion.slice(1).split('.')[0]); // 23

  if (major >= 18) {
    console.log(chalk.green('✔ Node version:', nodeVersion));
  } else {
    throw new Error(`Node.js v18+ is required (found ${nodeVersion})`);
  }

  // Check git
  try {
    const git = createGit();
    await git.version();
    console.log(chalk.green('✔ git found'));
  } catch {
    throw new Error('git is required but not found');
  }
}

export async function findConfigPaths(): Promise<{ cline?: string; claude?: string }> {
  const home = homedir();
  const platform = process.platform;

  type Paths = { cline: string; claude: string };
  let candidates: Paths[] = [];

  if (platform === 'win32') {
    // Standard VS Code
    candidates.push({
      cline: join(process.env.APPDATA || '', 'Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(process.env.APPDATA || '', 'Claude/claude_desktop_config.json'),
    });
    // VS Code Insiders
    candidates.push({
      cline: join(process.env.APPDATA || '', 'Code - Insiders/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(process.env.APPDATA || '', 'Claude/claude_desktop_config.json'),
    });
  } else if (platform === 'linux') {
    // Remote‐SSH / WSL
    candidates.push({
      cline: join(home, '.vscode-server/data/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(home, '.vscode-server/data/User/globalStorage/saoudrizwan.claude-dev/settings/claude_desktop_config.json'),
    });
    // Local VS Code
    candidates.push({
      cline: join(home, '.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(home, '.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/claude_desktop_config.json'),
    });
  } else {
    // macOS
    candidates.push({
      cline: join(home, 'Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(home, 'Library/Application Support/Claude/claude_desktop_config.json'),
    });
  }

  const result: { cline?: string; claude?: string } = {};

  for (const { cline, claude } of candidates) {
    try {
      await access(cline);
      result.cline = cline;
      console.log(chalk.green(`✔ Cline config found at ${cline}`));
    } catch {
      // not found here
    }

    try {
      await access(claude);
      result.claude = claude;
      console.log(chalk.green(`✔ Claude Desktop config found at ${claude}`));
    } catch {
      // not found here
    }

    // stop as soon as we find something
    if (result.cline || result.claude) break;
  }

  if (!result.cline && !result.claude) {
    throw new Error('No Cline or Claude Desktop configuration found');
  }

  return result;
}

export async function setupDeeboDirectory(config: SetupConfig): Promise<void> {
  let needsCleanup = false;

  try {
    await access(config.deeboPath);
    // Directory exists, ask for confirmation
    const { confirm } = await inquirer.prompt([{
      type: 'confirm',
      name: 'confirm',
      message: 'Deebo is already installed. Update to latest version?',
      default: true
    }]);

    if (!confirm) {
      console.log(chalk.yellow('Installation cancelled.'));
      process.exit(0);
    }

    needsCleanup = true;
  } catch (err) {
    // Directory doesn't exist, create it
    await mkdir(config.deeboPath, { recursive: true });
  }

  // Clean up if needed
  if (needsCleanup) {
    const { rm } = await import('fs/promises');
    await rm(config.deeboPath, { recursive: true, force: true });
    console.log(chalk.green('✔ Removed existing installation'));
    await mkdir(config.deeboPath, { recursive: true });
  }

  console.log(chalk.green('✔ Created Deebo directory'));

  // Clone repository
  const git = createGit();
  await git.clone(DEEBO_REPO, config.deeboPath);
  console.log(chalk.green('✔ Cloned Deebo repository'));

  // Install dependencies
  const { execSync } = await import('child_process');
  execSync('npm install', { cwd: config.deeboPath });
  console.log(chalk.green('✔ Installed dependencies'));

  // Build project
  execSync('npm run build', { cwd: config.deeboPath });
  console.log(chalk.green('✔ Built project'));
}

export async function writeEnvFile(config: SetupConfig): Promise<void> {
  const envContent = `MOTHER_HOST=${config.motherHost}
MOTHER_MODEL=${config.motherModel}
SCENARIO_HOST=${config.scenarioHost}
SCENARIO_MODEL=${config.scenarioModel}
${getApiKeyEnvVar(config.motherHost)}=${config.apiKey}
USE_MEMORY_BANK=true
NODE_ENV=development`;

  await writeFile(config.envPath, envContent);
  console.log(chalk.green('✔ Created environment file'));
}

export async function updateMcpConfig(config: SetupConfig): Promise<void> {
  const deeboConfig = {
    autoApprove: [],
    disabled: false,
    timeout: 30,
    command: 'node',
    args: [
      '--experimental-specifier-resolution=node',
      '--experimental-modules',
      '--max-old-space-size=4096',
      join(config.deeboPath, 'build/index.js')
    ],
    env: {
      NODE_ENV: 'development',
      USE_MEMORY_BANK: 'true',
      MOTHER_HOST: config.motherHost,
      MOTHER_MODEL: config.motherModel,
      SCENARIO_HOST: config.scenarioHost,
      SCENARIO_MODEL: config.scenarioModel,
      [getApiKeyEnvVar(config.motherHost)]: config.apiKey
    },
    transportType: 'stdio'
  };

  // Update Cline config if available
  if (config.clineConfigPath) {
    const clineConfig = JSON.parse(await readFile(config.clineConfigPath, 'utf8')) as McpConfig;
    clineConfig.mcpServers.deebo = deeboConfig;
    await writeFile(config.clineConfigPath, JSON.stringify(clineConfig, null, 2));
    console.log(chalk.green('✔ Updated Cline configuration'));
  }

  // Update Claude config if available
  if (config.claudeConfigPath) {
    const claudeConfig = JSON.parse(await readFile(config.claudeConfigPath, 'utf8')) as McpConfig;
    claudeConfig.mcpServers.deebo = deeboConfig;
    await writeFile(config.claudeConfigPath, JSON.stringify(claudeConfig, null, 2));
    console.log(chalk.green('✔ Updated Claude Desktop configuration'));
  }
}

function getDefaultModel(host: string): string {
  switch (host) {
    case 'openrouter':
      return 'anthropic/claude-3.5-sonnet';
    case 'anthropic':
      return 'claude-3-sonnet-20240229';
    case 'gemini':
      return 'gemini-1.5-pro';
    default:
      return 'anthropic/claude-3.5-sonnet';
  }
}

function getApiKeyEnvVar(host: string): string {
  switch (host) {
    case 'openrouter':
      return 'OPENROUTER_API_KEY';
    case 'openai':
      return 'OPENAI_API_KEY';
    case 'anthropic':
      return 'ANTHROPIC_API_KEY';
    case 'gemini':
      return 'GEMINI_API_KEY';
    default:
      return 'OPENROUTER_API_KEY';
  }
}

// Removed the pingInstallation function - implemented directly in index.ts

=== packages/deebo-setup/src/types.ts ===

import { z } from 'zod';

export const LlmHostSchema = z.enum(['openrouter', 'anthropic', 'gemini']);
export type LlmHost = z.infer<typeof LlmHostSchema>;

export const McpConfigSchema = z.object({
  mcpServers: z.record(z.object({
    autoApprove: z.array(z.string()),
    disabled: z.boolean(),
    timeout: z.number(),
    command: z.string(),
    args: z.array(z.string()),
    env: z.record(z.string()),
    transportType: z.string()
  }))
});

export type McpConfig = z.infer<typeof McpConfigSchema>;

export const LlmModelSchema = z.string();
export type LlmModel = z.infer<typeof LlmModelSchema>;

export interface SetupConfig {
  deeboPath: string;
  envPath: string;
  motherHost: LlmHost;
  motherModel: LlmModel;
  scenarioHost: LlmHost;
  scenarioModel: LlmModel;
  apiKey: string;
  clineConfigPath?: string;
  claudeConfigPath?: string;
}

=== packages/deebo-setup/src/index.ts ===

#!/usr/bin/env node
import { homedir } from 'os';
import { join } from 'path';
import inquirer from 'inquirer';
import chalk from 'chalk';
import { LlmHostSchema } from './types.js';
import {
  checkPrerequisites,
  findConfigPaths,
  setupDeeboDirectory,
  writeEnvFile,
  updateMcpConfig
} from './utils.js';

async function main() {
  // Check if this is a ping command
  if (process.argv.length > 2 && process.argv[2] === 'ping') {
    try {
      console.log(chalk.blue('Pinging Deebo installation tracker...'));
      // Simple ping with no extra dependencies or complexity
      const response = await fetch('https://deebo-active-counter.ramnag2003.workers.dev/ping', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ hash: `user-${Date.now()}` })
      });
      
      if (response.ok) {
        console.log(chalk.green('✓ Successfully pinged Deebo installation tracker'));
      } else {
        console.log(chalk.yellow('⚠ Failed to ping installation tracker'));
      }
    } catch (error) {
      console.log(chalk.yellow('⚠ Could not reach installation tracker'));
    }
    return;
  }

  try {
    // Check prerequisites
    await checkPrerequisites();

    // Find config paths
    const configPaths = await findConfigPaths();

    // Get Mother agent configuration
    const defaultModels: Record<string, string> = {
      openrouter: 'anthropic/claude-3.5-sonnet',
      openai: 'gpt-4o',
      anthropic: 'claude-3-5-sonnet-20241022',
      gemini: 'gemini-2.5-pro-preview-03-25'
    };

    // Get Mother agent configuration
    const { motherHost } = await inquirer.prompt([{
      type: 'list',
      name: 'motherHost',
      message: 'Choose LLM host for Mother agent:',
      choices: Object.keys(defaultModels)
    }]);

    const parsedMotherHost = LlmHostSchema.parse(motherHost);

    const { motherModel } = await inquirer.prompt([{
      type: 'input',
      name: 'motherModel',
      message: `Enter model for Mother agent (press Enter for ${defaultModels[parsedMotherHost]}):`,
      default: defaultModels[parsedMotherHost]
    }]);

    // Get Scenario agent configuration
    const { scenarioHost } = await inquirer.prompt([{
      type: 'list',
      name: 'scenarioHost',
      message: 'Choose LLM host for Scenario agents (press Enter to use same as Mother):',
      choices: Object.keys(defaultModels),
      default: parsedMotherHost
    }]);

    const parsedScenarioHost = LlmHostSchema.parse(scenarioHost);

    const { scenarioModel } = await inquirer.prompt([{
      type: 'input',
      name: 'scenarioModel',
      message: `Enter model for Scenario agents (press Enter for ${defaultModels[parsedScenarioHost]}):`,
      default: defaultModels[parsedScenarioHost]
    }]);

    // Get API key
    const { apiKey } = await inquirer.prompt([{
      type: 'password',
      name: 'apiKey',
      message: `Enter your ${motherHost.toUpperCase()}_API_KEY:`
    }]);

    // Show API key preview
    console.log(chalk.dim(`API key preview: ${apiKey.substring(0, 8)}...`));
    const { confirmKey } = await inquirer.prompt([{
      type: 'confirm',
      name: 'confirmKey',
      message: 'Is this API key correct?',
      default: true
    }]);

    if (!confirmKey) {
      throw new Error('API key confirmation failed. Please try again.');
    }

    // Setup paths
    const home = homedir();
    const deeboPath = join(home, '.deebo');
    const envPath = join(deeboPath, '.env');

    // Create config object
    const config = {
      deeboPath,
      envPath,
      motherHost: parsedMotherHost,
      motherModel,
      scenarioHost: parsedScenarioHost,
      scenarioModel,
      apiKey,
      clineConfigPath: configPaths.cline,
      claudeConfigPath: configPaths.claude
    };

    // Setup Deebo
    await setupDeeboDirectory(config);
    await writeEnvFile(config);
    await updateMcpConfig(config);

    console.log(chalk.green('\n✔ Deebo installation complete!'));
    console.log(chalk.blue('\nNext steps:'));
    console.log('1. Restart your MCP client (Cline/Claude Desktop)');
    console.log('2. Run npx deebo-doctor to verify the installation (use --verbose for more details)');
    
  } catch (error) {
    console.error(chalk.red('\n✖ Installation failed:'));
    console.error(error instanceof Error ? error.message : String(error));
    process.exit(1);
  }
}

main();

=== packages/deebo-setup/package.json ===

{
  "name": "deebo-setup",
  "version": "1.0.81",
  "description": "System installer for Deebo debugging tool",
  "type": "module",
  "bin": {
    "deebo-setup": "build/index.js"
  },
  "scripts": {
    "build": "tsc",
    "start": "node build/index.js"
  },
  "dependencies": {
    "chalk": "^5.3.0",
    "inquirer": "^9.2.16",
    "simple-git": "^3.22.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/inquirer": "^9.0.7",
    "@types/node": "^20.11.28",
    "typescript": "^5.4.2"
  }
}

=== packages/deebo-doctor/src/types.ts ===

export interface CheckResult {
  name: string;
  status: 'pass' | 'fail' | 'warn';
  message: string;
  details?: string;
}

export interface DoctorConfig {
  verbose: boolean;
  deeboPath: string;
  logPath?: string;
}

export interface SystemCheck {
  name: string;
  check: (config: DoctorConfig) => Promise<CheckResult>;
  fix?: (config: DoctorConfig) => Promise<void>;
}

=== packages/deebo-doctor/src/checks.ts ===

import { CheckResult, DoctorConfig, SystemCheck } from './types.js';
import { homedir } from 'os';
import { join } from 'path';
import { access, readFile } from 'fs/promises';
import { simpleGit as createGit } from 'simple-git';

export const nodeVersionCheck: SystemCheck = {
  name: 'Node.js Version',
  async check() {
    const version = process.version;
    if (version.startsWith('v18') || version.startsWith('v20') || version.startsWith('v22')) {
      return {
        name: 'Node.js Version',
        status: 'pass',
        message: `Node ${version} detected`,
      };
    }
    return {
      name: 'Node.js Version',
      status: 'fail',
      message: `Node.js v18+ required, found ${version}`,
      details: 'Install Node.js v18 or later from https://nodejs.org'
    };
  }
};

export const gitCheck: SystemCheck = {
  name: 'Git Installation',
  async check() {
    try {
      const git = createGit();
      const version = await git.version();
      return {
        name: 'Git Installation',
        status: 'pass',
        message: `Git ${version} detected`,
      };
    } catch {
      return {
        name: 'Git Installation',
        status: 'fail',
        message: 'Git not found',
        details: 'Install Git from https://git-scm.com'
      };
    }
  }
};

export const mcpToolsCheck: SystemCheck = {
  name: 'MCP Tools',
  async check() {
    const results: CheckResult[] = [];
    
    // Check git-mcp
    try {
      const { execSync } = await import('child_process');
      execSync('uvx mcp-server-git --help');
      results.push({
        name: 'git-mcp',
        status: 'pass',
        message: 'git-mcp installed'
      });
    } catch {
      results.push({
        name: 'git-mcp',
        status: 'fail',
        message: 'git-mcp not found',
        details: 'Install with: uvx mcp-server-git --help'
      });
    }

    // Check desktop-commander
    try {
      const { execSync } = await import('child_process');
      execSync('npx @wonderwhy-er/desktop-commander --help 2>/dev/null');
      results.push({
        name: 'desktop-commander',
        status: 'pass',
        message: 'desktop-commander installed'
      });
    } catch {
      results.push({
        name: 'desktop-commander',
        status: 'fail',
        message: 'desktop-commander not found',
        details: 'Install with: npx @wonderwhy-er/desktop-commander setup'
      });
    }

    // Aggregate results
    const allPass = results.every(r => r.status === 'pass');
    return {
      name: 'MCP Tools',
      status: allPass ? 'pass' : 'fail',
      message: allPass ? 'All MCP tools installed' : 'Some MCP tools missing',
      details: results.map(r => `${r.name}: ${r.message}`).join('\n')
    };
  }
};

export const toolPathsCheck: SystemCheck = {
  name: 'Tool Paths', 
  async check() {
    const results: CheckResult[] = [];
    const isWindows = process.platform === 'win32';
    const { execSync } = await import('child_process');
    
    // Check npx
    try {
      const npxPath = execSync(
        isWindows ? 'cmd.exe /c where npx.cmd' : 'which npx'
      ).toString().trim().split('\n')[0]; // Take first path if multiple returned
      results.push({
        name: 'npx',
        status: 'pass',
        message: 'npx found',
        details: `Path: ${npxPath}`
      });
    } catch {
      results.push({
        name: 'npx',
        status: 'fail',
        message: 'npx not found',
        details: 'Install Node.js to get npx'
      });
    }

    // Check uvx 
    try {
      const uvxPath = execSync(
        isWindows ? 'cmd.exe /c where uvx.exe' : 'which uvx'
      ).toString().trim().split('\n')[0]; // Take first path if multiple returned
      results.push({
        name: 'uvx',
        status: 'pass',
        message: 'uvx found',
        details: `Path: ${uvxPath}`
      });
    } catch {
      results.push({
        name: 'uvx',
        status: 'fail',
        message: 'uvx not found',
        details: isWindows ? 'Install uv using pip: pip install uv' : 'Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh'
      });
    }

    // Aggregate results
    const allPass = results.every(r => r.status === 'pass');
    return {
      name: 'Tool Paths',
      status: allPass ? 'pass' : 'fail', 
      message: allPass ? 'All tool paths found' : 'Some tool paths missing',
      details: results.map(r => `${r.name}: ${r.details || r.message}`).join('\n')
    };
  }
};

export const configFilesCheck: SystemCheck = {
  name: 'Configuration Files',
  async check(config: DoctorConfig) {
    const home = homedir();
    const isWindows = process.platform === 'win32';
    
    const paths = isWindows ? {
      cline: join(process.env.APPDATA || '', 'Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(process.env.APPDATA || '', 'Claude/claude_desktop_config.json'),
      env: join(config.deeboPath, '.env'),
      tools: join(config.deeboPath, 'config/tools.json')
    } : {
      cline: join(home, 'Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json'),
      claude: join(home, 'Library/Application Support/Claude/claude_desktop_config.json'),
      env: join(config.deeboPath, '.env'),
      tools: join(config.deeboPath, 'config/tools.json')
    };

    const results: CheckResult[] = [];

    // Check each config file
    for (const [name, path] of Object.entries(paths)) {
      try {
        await access(path);
        const content = await readFile(path, 'utf8');
        
        // Parse JSON if applicable
        if (name !== 'env') {
          const json = JSON.parse(content);
          
          // Check if Deebo is configured in MCP configs
          if ((name === 'cline' || name === 'claude') && (!json.mcpServers?.deebo)) {
            results.push({
              name,
              status: 'fail',
              message: `${name} config exists but Deebo not configured`,
              details: `Path: ${path}\nAdd Deebo configuration to mcpServers`
            });
            continue;
          }

          // Check tools.json structure
          if (name === 'tools' && (!json.tools?.desktopCommander || !json.tools?.['git-mcp'])) {
            results.push({
              name,
              status: 'fail',
              message: `${name} config exists but missing required tools`,
              details: `Path: ${path}\nMissing one or more required tools: desktopCommander, git-mcp`
            });
            continue;
          }
        }

        results.push({
          name,
          status: 'pass',
          message: `${name} config found and valid`,
          details: `Path: ${path}`
        });
      } catch {
        results.push({
          name,
          status: 'fail',
          message: `${name} config not found or invalid`,
          details: `Expected at: ${path}`
        });
      }
    }

    // Aggregate results
    const allPass = results.every(r => r.status === 'pass');
    return {
      name: 'Configuration Files',
      status: allPass ? 'pass' : 'fail',
      message: allPass ? 'All configuration files valid' : 'Some configuration files missing or invalid',
      details: results.map(r => `${r.name}: ${r.message}\n${r.details || ''}`).join('\n\n')
    };
  }
};

export const apiKeysCheck: SystemCheck = {
  name: 'API Keys',
  async check(config: DoctorConfig) {
    const envPath = join(config.deeboPath, '.env');
    try {
      const content = await readFile(envPath, 'utf8');
      const lines = content.split('\n');
      const results: CheckResult[] = [];

      // Check each potential API key
      const keyChecks = {
        OPENROUTER_API_KEY: 'sk-or-v1-',
        OPENAI_API_KEY: 'sk-',
        ANTHROPIC_API_KEY: 'sk-ant-',
        GEMINI_API_KEY: 'AI'
      };

      for (const [key, prefix] of Object.entries(keyChecks)) {
        const line = lines.find(l => l.startsWith(key));
        if (!line) {
          results.push({
            name: key,
            status: 'warn',
            message: `${key} not found`
          });
          continue;
        }

        const value = line.split('=')[1]?.trim();
        if (!value || !value.startsWith(prefix)) {
          results.push({
            name: key,
            status: 'warn',
            message: `${key} may be invalid`,
            details: `Expected prefix: ${prefix}`
          });
          continue;
        }

        results.push({
          name: key,
          status: 'pass',
          message: `${key} found and valid`
        });
      }

      // Aggregate results
      const allPass = results.some(r => r.status === 'pass');
      return {
        name: 'API Keys',
        status: allPass ? 'pass' : 'warn',
        message: allPass ? 'At least one valid API key found' : 'No valid API keys found',
        details: results.map(r => `${r.name}: ${r.message}`).join('\n')
      };
    } catch {
      return {
        name: 'API Keys',
        status: 'fail',
        message: 'Could not read .env file',
        details: `Expected at ${envPath}`
      };
    }
  }
};

export const allChecks = [
  nodeVersionCheck,
  gitCheck,
  toolPathsCheck,
  mcpToolsCheck,
  configFilesCheck,
  apiKeysCheck
];

=== packages/deebo-doctor/src/index.ts ===

#!/usr/bin/env node
import { homedir } from 'os';
import { join } from 'path';
import chalk from 'chalk';
import { allChecks } from './checks.js';
import { DoctorConfig } from './types.js';

async function main() {
  // Parse arguments
  const verbose = process.argv.includes('--verbose');
  const deeboPath = join(homedir(), '.deebo');
  const logPath = verbose ? join(deeboPath, 'doctor.log') : undefined;

  const config: DoctorConfig = {
    verbose,
    deeboPath,
    logPath
  };

  console.log(chalk.bold('\nDeebo Doctor - System Health Check\n'));

  // Run all checks
  let allPassed = true;
  for (const check of allChecks) {
    try {
      const result = await check.check(config);
      
      // Print result
      const icon = result.status === 'pass' ? '✔' : result.status === 'warn' ? '⚠' : '✖';
      const color = result.status === 'pass' ? chalk.green : result.status === 'warn' ? chalk.yellow : chalk.red;
      
      console.log(color(`${icon} ${result.name}: ${result.message}`));
      
      if (verbose && result.details) {
        console.log(chalk.dim(result.details));
      }

      if (result.status === 'fail') {
        allPassed = false;
      }
    } catch (err) {
      console.error(chalk.red(`✖ ${check.name}: Error running check`));
      if (verbose) {
        console.error(chalk.dim(err));
      }
      allPassed = false;
    }
  }

  // Print summary
  console.log('\n' + (allPassed 
    ? chalk.green('✔ All checks passed!')
    : chalk.red('✖ Some checks failed. Run with --verbose for more details.')));

  process.exit(allPassed ? 0 : 1);
}

main().catch(err => {
  console.error(chalk.red('\n✖ Error running doctor:'), err);
  process.exit(1);
});

=== packages/deebo-doctor/package.json ===

{
  "name": "deebo-doctor",
  "version": "1.0.8",
  "description": "Health check tool for Deebo debugging system",
  "type": "module",
  "bin": {
    "deebo-doctor": "build/index.js"
  },
  "scripts": {
    "build": "tsc",
    "start": "node build/index.js"
  },
  "dependencies": {
    "chalk": "^5.3.0",
    "inquirer": "^9.2.16",
    "simple-git": "^3.22.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/inquirer": "^9.0.7",
    "@types/node": "^20.11.28",
    "typescript": "^5.4.2"
  }
}

=== config/tools.json ===

{
  "tools": {
    "desktopCommander": {
      "command": "{npxPath}",
      "args": [
        "@wonderwhy-er/desktop-commander"
      ]
    },
    "git-mcp": {
      "command": "{uvxPath}",
      "args": [
        "mcp-server-git",
        "--repository",
        "{repoPath}"
      ]
    }
  }
}
=== package.json ===

{
  "name": "deebo-prototype",
  "version": "1.0.0",
  "main": "build/index.js",
  "bin": {
    "deebo": "build/index.js"
  },
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node --experimental-specifier-resolution=node --experimental-modules --max-old-space-size=4096 build/index.js",
    "dev": "tsc --watch & node --experimental-specifier-resolution=node --experimental-modules --max-old-space-size=4096 --watch build/index.js",
    "setup": "bash setup.sh",
    "setup:win": "powershell -ExecutionPolicy Bypass -File .\\setup.ps1",
    "check-env": "node check-env.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "Agentic Debugging System that integrates with Git and Filesystem MCP servers",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.39.0",
    "@google/generative-ai": "^0.24.0",
    "@modelcontextprotocol/sdk": "^1.7.0",
    "@modelcontextprotocol/server-filesystem": "^2025.1.14",
    "@wonderwhy-er/desktop-commander": "^0.1.31",
    "cors": "^2.8.5",
    "dockerode": "^4.0.0",
    "dotenv": "^16.4.7",
    "express": "^5.0.1",
    "openai": "^4.91.1",
    "p-limit": "^6.2.0",
    "simple-git": "^3.27.0",
    "urlpattern-polyfill": "^10.0.0",
    "uuid": "^11.1.0",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/dockerode": "^3.3.23",
    "@types/express": "^5.0.1",
    "@types/node": "^22.13.14",
    "@types/uuid": "^9.0.8",
    "typescript": "^5.8.2"
  },
  "resolutions": {
    "@modelcontextprotocol/sdk": "1.7.0"
  }
}

=== tsconfig.json ===

{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./build",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "allowJs": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "lib": ["ES2022"],
    "types": ["node"]
  },
  "include": ["src/**/*"]
}

=== README.md ===


# Deebo: Your AI Agent's Debugging Partner
[![npm version](https://img.shields.io/npm/v/deebo-setup.svg)](https://www.npmjs.com/package/deebo-setup)
[![GitHub stars](https://img.shields.io/github/stars/snagasuri/deebo-prototype?style=social)](https://github.com/snagasuri/deebo-prototype)
[![Active installs](https://img.shields.io/endpoint?url=https://deebo-active-counter.ramnag2003.workers.dev/active)](https://github.com/snagasuri/deebo-prototype)

Deebo is an autonomous debugging system that AI coding agents (Claude, Cline, Cursor, etc.) can delegate tricky bugs to using the Model Context Protocol (MCP). It runs structured investigations in parallel Git branches to test hypotheses, validate fixes, and helps you move faster. If your main coding agent is like a single-threaded process, Deebo introduces multi-threadedness to your development workflow.

**feedback, questions/support? dm me on x @sriramenn or open an issue here**

**If you think your team can benefit from Deebo, we’d love to hear from you.**
We’re partnering with teams who use AI agents to write production code and want to maximize their productivity.
Reach out for a live walkthrough, custom setup support, or to explore early access to enterprise features.

<video src="https://github.com/user-attachments/assets/756d35b4-4f77-48de-bd1a-86f76360279e" controls width="100%"></video>
**40-second sped-up video of Deebo in action on a real codebase**


Deebo scales to production codebases, too. Here's [an example of Deebo solving the test53 linearizer failure $100 tinygrad bug bounty](https://github.com/snagasuri/deebo-prototype/tree/master/memory-bank/9bd38e9840d3/sessions/session-1744006973678) by spawning 17 scenario agents and coming up with 2 valid fixes. Check out [progress.md](https://github.com/snagasuri/deebo-prototype/blob/master/memory-bank/9bd38e9840d3/progress.md) for just the solution.

## 🚀 Quick Install (for Cline/Claude Desktop users) 
```bash
npx deebo-setup
```
That's it! Follow the prompts to configure your API key and you're ready to go.

**show us you're alive!!**
```bash
npx deebo-setup ping
```
## Cursor users: https://cursor.directory/mcp/deebo

<details>
<summary>🛠️ Manual Installation (for other setups)</summary>

If you're not using Cline or Claude Desktop, follow these steps:

1. Clone the repo:
   ```bash
   git clone https://github.com/snagasuri/deebo-prototype.git
   cd deebo-prototype
   ```

2. Install dependencies:
   ```bash
   npm install
   npm run build
   ```

3. Install required MCP tools:
   ```bash
   # Install uv/uvx
   curl -LsSf https://astral.sh/uv/install.sh | sh

   # Install git-mcp
   uvx mcp-server-git --help

   # Install desktop-commander
   npx @wonderwhy-er/desktop-commander@latest setup
   ```

4. Configure your MCP client to use Deebo 

### MCP Configuration
```json
{
  "mcpServers": {
    "deebo": {
      "autoApprove": [],
      "disabled": false,
      "timeout": 30,
      "command": "node",
      "args": [
        "--experimental-specifier-resolution=node",
        "--experimental-modules",
        "--max-old-space-size=4096",
        "/absolute/path/to/deebo/build/index.js"
      ],
      "env": {
        "NODE_ENV": "development",
        "USE_MEMORY_BANK": "true",
        "MOTHER_HOST": "openrouter",
        "MOTHER_MODEL": "anthropic/claude-3.5-sonnet",
        "SCENARIO_HOST": "openrouter",
        "SCENARIO_MODEL": "anthropic/claude-3.5-sonnet",
        "OPENROUTER_API_KEY": "sk-or-v1-..."
      },
      "transportType": "stdio"
    }
  }
}
```
</details>

<details>
<summary>🔧 Development Guide</summary>

### Prerequisites
- **Git**: For version control
- **Node.js**: v18+ (includes npm)
- **Python**: 3.10+ (for git-mcp)

### Configuration Files
- **Cline:** `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`
- **Claude Desktop:** `~/Library/Application Support/Claude/claude_desktop_config.json`

### LLM Support
Deebo supports OpenRouter, Anthropic, OpenAI SDK, and Gemini models. Configure via environment variables:
- `MOTHER_HOST`: LLM provider for mother agent
- `SCENARIO_HOST`: LLM provider for scenario agents
- `[PROVIDER]_API_KEY`: API key for chosen provider
- Any other OpenAI-compatible API endpoint
  - `OPENAI_API_KEY` to your API key (e.g., `'ollama'` for Ollama)
  - `OPENAI_BASE_URL` to your API endpoint (e.g., `'http://localhost:11434/v1'` for Ollama)

See `src/util/agent-utils.ts` for supported models and configuration details.
</details>

## 📜 License

This project is licensed under the Apache License, Version 2.0 - see the [LICENSE](LICENSE) file for details.

Copyright 2025 Sriram Nagasuri
